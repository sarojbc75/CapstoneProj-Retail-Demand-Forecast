{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Retail    \n",
    "## Prepared and Submitted By: Saroj Kumar Bisi 04.09.2020\n",
    "\n",
    "**DESCRIPTION**\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    " * Demand Forecast is one of the key tasks in Supply Chain and Retail Domain in general. It is key in effective operation and optimization of retail supply chain. Effectively solving this problem requires knowledge about a wide range of tricks in Data Sciences and good understanding of ensemble techniques.\n",
    " \n",
    " * You are required to predict sales for each Store-Day level for one month. All the features will be provided and actual sales that happened during that month will also be provided for model evaluation. \n",
    " \n",
    " * You are required to predict Sentiment or Satisfaction of a purchase based on multiple features and review text.\n",
    "\n",
    "**Data Snapshot**\n",
    " * Training Data Description: Historic sales at Store-Day level for about two years for a retail giant, for more than 1000 stores. Also, other sale influencers like, whether on a particular day the store was fully open or closed for renovation, holiday and special event details, are also provided\n",
    " Downlod the **data sets** from _**[here](https://github.com/Simplilearn-Edu/Artificial-Intelligence-Capstone-Project-Datasets)**_.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SC=StandardScaler()\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\n",
    "from xgboost import XGBRegressor,XGBRFRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "storeList=np.arange(1,11) #  Take data only 10 stores\n",
    "n_splits=5\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,LSTM,Flatten,Dropout,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 1\n",
    "\n",
    "**Exploratory Data Analysis (EDA) and Linear Regression:**\n",
    "\n",
    "1. Transform the variables by using data manipulation techniques like, One-Hot Encoding.\n",
    "2. Perform an EDA (Exploratory Data Analysis) to see the impact of variables over Sales.\n",
    "3. Apply Linear Regression to predict the forecast and evaluate different accuracy metrices like RMSE (Root Mean Squared Error)\n",
    "   and MAE(Mean Absolute Error) and determine which metric makes more sense. Can there be a better accuracy metric? \n",
    "   \n",
    "   a) Train a single model for all stores, using storeId as a feature.\n",
    "   \n",
    "   b) Train separate model for each store.\n",
    "   \n",
    "   c) Which performs better and Why? [In the first case, parameters are shared and not very free but not in second case].\n",
    "   \n",
    "   d) Try Ensemble of b) and c). What are the findings?\n",
    "   \n",
    "   e) Use Regularized Regression. It should perform better in an unseen test set. Any insights??\n",
    "   \n",
    "   f) Open-ended modeling to get possible predictions.\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train data\n",
    "traindata=pd.read_csv('train_data.csv')\n",
    "test_hiddata=pd.read_csv('test_data_hidden.csv')\n",
    "testdata=pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          2  2015-06-30   5735        568     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo  StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1             0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hiddata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Open  Promo  StateHoliday  SchoolHoliday\n",
       "0      1          5  2015-07-31     1      1             0              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train data:  (982644, 9)\n",
      "the shape of test_hidden data:  (34565, 9)\n",
      "the shape of test data:  (34565, 7)\n"
     ]
    }
   ],
   "source": [
    "print('the shape of train data: ', traindata.shape)\n",
    "print('the shape of test_hidden data: ', test_hiddata.shape)\n",
    "print('the shape of test data: ', testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations:\n",
    "#shape of train data and test hidden data is same and these two can be merged for performing EDA together\n",
    "# testdata does not contain 'Customers' feature where as train data contains the same feature. It means we can exclude this feature from train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing,EDA & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of combined data is:  (1017209, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106</td>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          2  2015-06-30   5735        568     1      1            0   \n",
       "1      2          2  2015-06-30   9863        877     1      1            0   \n",
       "2      3          2  2015-06-30  13261       1072     1      1            0   \n",
       "3      4          2  2015-06-30  13106       1488     1      1            0   \n",
       "4      5          2  2015-06-30   6635        645     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              0  \n",
       "1              0  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the train0 and train_hidden0 are having same features its worth to merge them together and perform the EDA\n",
    "#Data merge\n",
    "dataSet=pd.concat([traindata,test_hiddata])\n",
    "print('shape of combined data is: ',dataSet.shape)\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store            0\n",
       "DayOfWeek        0\n",
       "Date             0\n",
       "Sales            0\n",
       "Customers        0\n",
       "Open             0\n",
       "Promo            0\n",
       "StateHoliday     0\n",
       "SchoolHoliday    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Check for null values\n",
    "dataSet.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1017209 entries, 0 to 34564\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   Store          1017209 non-null  int64 \n",
      " 1   DayOfWeek      1017209 non-null  int64 \n",
      " 2   Date           1017209 non-null  object\n",
      " 3   Sales          1017209 non-null  int64 \n",
      " 4   Customers      1017209 non-null  int64 \n",
      " 5   Open           1017209 non-null  int64 \n",
      " 6   Promo          1017209 non-null  int64 \n",
      " 7   StateHoliday   1017209 non-null  object\n",
      " 8   SchoolHoliday  1017209 non-null  int64 \n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 77.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    886058\n",
       "0    100101\n",
       "a     20260\n",
       "b      6690\n",
       "c      4100\n",
       "Name: StateHoliday, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.StateHoliday.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    886058\n",
       "0    100101\n",
       "a     20260\n",
       "b      6690\n",
       "c      4100\n",
       "Name: StateHoliday, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.StateHoliday.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lets analyzse the data and see if a,b,c catagory indicates any holiday or not !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015-04-06    1115\n",
       "2013-12-25    1115\n",
       "2014-05-29    1115\n",
       "2014-05-01    1115\n",
       "2015-05-01    1115\n",
       "2013-05-09    1115\n",
       "2015-04-03    1115\n",
       "2015-05-14    1115\n",
       "2014-04-18    1115\n",
       "2013-03-29    1115\n",
       "2015-05-25    1115\n",
       "2013-10-03    1115\n",
       "2013-12-26    1115\n",
       "2014-01-01    1115\n",
       "2014-04-21    1115\n",
       "2013-05-01    1115\n",
       "2013-04-01    1115\n",
       "2013-05-20    1115\n",
       "2014-06-09    1115\n",
       "2013-01-01    1114\n",
       "2015-01-01    1079\n",
       "2014-10-03     935\n",
       "2014-12-25     935\n",
       "2014-12-26     935\n",
       "2013-05-30     766\n",
       "2014-06-19     766\n",
       "2015-06-04     766\n",
       "2013-11-01     579\n",
       "2014-11-01     399\n",
       "2014-01-06     309\n",
       "2015-01-06     309\n",
       "2013-01-06     309\n",
       "2013-08-15     180\n",
       "2014-10-31     167\n",
       "2013-10-31     167\n",
       "2014-11-19      75\n",
       "2013-11-20      75\n",
       "Name: Date, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet[dataSet.StateHoliday.isin(['a','b','c'])].Date.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From data analysis of a, b, c it seems that StateHoliday=='a','b','c' seems to be an actual holiday \n",
    "    example(01.01. or 25.12, 26.12 etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing char '0' with numeric 0 and replace 'a','b','c', with 1\n",
    "dataSet.StateHoliday.replace('0',0,inplace=True)\n",
    "dataSet.StateHoliday.replace(['a','b','c'],1,inplace=True)\n",
    "\n",
    "# Date  feature is of object datatype. We can convert it  to Datetime\n",
    "dataSet['Date']=pd.to_datetime(dataSet['Date'])\n",
    "#dataSet['Date']=dataSet.Date.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    986159\n",
       "1     31050\n",
       "Name: StateHoliday, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.StateHoliday.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1017209 entries, 0 to 34564\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   Store          1017209 non-null  int64         \n",
      " 1   DayOfWeek      1017209 non-null  int64         \n",
      " 2   Date           1017209 non-null  datetime64[ns]\n",
      " 3   Sales          1017209 non-null  int64         \n",
      " 4   Customers      1017209 non-null  int64         \n",
      " 5   Open           1017209 non-null  int64         \n",
      " 6   Promo          1017209 non-null  int64         \n",
      " 7   StateHoliday   1017209 non-null  int64         \n",
      " 8   SchoolHoliday  1017209 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(8)\n",
      "memory usage: 77.6 MB\n"
     ]
    }
   ],
   "source": [
    "dataSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106</td>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek       Date  Sales  Customers  Open  Promo  StateHoliday  \\\n",
       "0      1          2 2015-06-30   5735        568     1      1             0   \n",
       "1      2          2 2015-06-30   9863        877     1      1             0   \n",
       "2      3          2 2015-06-30  13261       1072     1      1             0   \n",
       "3      4          2 2015-06-30  13106       1488     1      1             0   \n",
       "4      5          2 2015-06-30   6635        645     1      1             0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              0  \n",
       "1              0  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the Data Preprocessing steps on Train and Test Data separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.StateHoliday.replace('0',0,inplace=True)\n",
    "traindata.StateHoliday.replace(['a','b','c'],1,inplace=True)\n",
    "\n",
    "\n",
    "test_hiddata.StateHoliday.replace('0',0,inplace=True)\n",
    "test_hiddata.StateHoliday.replace(['a','b','c'],1,inplace=True)\n",
    "\n",
    "# Convert the Date column into  datatime and then split the date column into Day, Week, DayofYear for Train Data\n",
    "traindata['Date']=pd.to_datetime(traindata['Date'])\n",
    "traindata.insert(1,'Week',traindata['Date'].dt.week)\n",
    "traindata.insert(2,'Day',traindata['Date'].dt.day)\n",
    "traindata.insert(3,'DayofYear',traindata['Date'].dt.dayofyear)\n",
    "\n",
    "# Convert the Date column into  datatime and then split the date column into Day, Week, DayofYear for Test Data\n",
    "test_hiddata['Date']=pd.to_datetime(test_hiddata['Date'])\n",
    "test_hiddata.insert(1,'Week',test_hiddata['Date'].dt.week)\n",
    "test_hiddata.insert(2,'Day',test_hiddata['Date'].dt.day)\n",
    "test_hiddata.insert(3,'DayofYear',test_hiddata['Date'].dt.dayofyear)\n",
    "\n",
    "traindata_init= traindata # this is just to take a backup of actual train data\n",
    "test_hiddata_init=test_hiddata # this is just to take a backup of actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayofYear</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Week  Day  DayofYear  DayOfWeek       Date  Sales  Customers  Open  \\\n",
       "0      1    27   30        181          2 2015-06-30   5735        568     1   \n",
       "\n",
       "   Promo  StateHoliday  SchoolHoliday  \n",
       "0      1             0              0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayofYear</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Week  Day  DayofYear  DayOfWeek       Date  Sales  Customers  Open  \\\n",
       "0      1    31   31        212          5 2015-07-31   5263        555     1   \n",
       "\n",
       "   Promo  StateHoliday  SchoolHoliday  \n",
       "0      1             0              1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hiddata.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "# lets do pair plot to see the relationship between features and target(Sales).\n",
    "plt.figure(figsize=[7,10])\n",
    "plt.subplot(3,3,1)\n",
    "sns.pairplot(traindata,x_vars=['Store','Date','Sales'],y_vars=['Store','Date','Sales'],kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "# lets do pair plot to see the relationship between features and target(Sales).\n",
    "plt.figure(figsize=[7,10])\n",
    "plt.subplot(3,3,1)\n",
    "sns.pairplot(traindata,x_vars=['DayOfWeek','Customers','Sales'],y_vars=['DayOfWeek','Customers','Sales'],kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "# lets do pair plot to see the relationship between features and target(Sales).\n",
    "plt.figure(figsize=[7,10])\n",
    "plt.subplot(4,4,1)\n",
    "sns.pairplot(traindata,x_vars=['Open','Promo','StateHoliday','Sales'],y_vars=['Open','Promo','StateHoliday','Sales'],kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data distribution plot. \n",
    "plt.figure(figsize=[12,14])\n",
    "features=dataSet.columns\n",
    "n=1\n",
    "for f in features:\n",
    "    plt.subplot(10,4,n)\n",
    "    sns.distplot(dataSet[f], kde=False)\n",
    "    sns.despine()\n",
    "    n=n+1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayofYear</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.024410</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>-0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week</th>\n",
       "      <td>0.001467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067457</td>\n",
       "      <td>0.968224</td>\n",
       "      <td>-0.004208</td>\n",
       "      <td>0.052120</td>\n",
       "      <td>0.041524</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.065093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097123</td>\n",
       "      <td>0.006992</td>\n",
       "      <td>-0.014450</td>\n",
       "      <td>-0.005487</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>-0.117171</td>\n",
       "      <td>-0.067317</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DayofYear</th>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.968224</td>\n",
       "      <td>0.097123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>0.046971</td>\n",
       "      <td>0.037935</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>-0.023063</td>\n",
       "      <td>-0.004752</td>\n",
       "      <td>0.100981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DayOfWeek</th>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.004208</td>\n",
       "      <td>0.006992</td>\n",
       "      <td>-0.004873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.461249</td>\n",
       "      <td>-0.386213</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>-0.394777</td>\n",
       "      <td>-0.053762</td>\n",
       "      <td>-0.200570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.052120</td>\n",
       "      <td>-0.014450</td>\n",
       "      <td>0.046971</td>\n",
       "      <td>-0.461249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895700</td>\n",
       "      <td>0.679248</td>\n",
       "      <td>0.451383</td>\n",
       "      <td>-0.257671</td>\n",
       "      <td>0.076141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customers</th>\n",
       "      <td>0.024410</td>\n",
       "      <td>0.041524</td>\n",
       "      <td>-0.005487</td>\n",
       "      <td>0.037935</td>\n",
       "      <td>-0.386213</td>\n",
       "      <td>0.895700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618407</td>\n",
       "      <td>0.316378</td>\n",
       "      <td>-0.230050</td>\n",
       "      <td>0.064804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>-0.527372</td>\n",
       "      <td>0.679248</td>\n",
       "      <td>0.618407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294143</td>\n",
       "      <td>-0.383098</td>\n",
       "      <td>0.076865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promo</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.117171</td>\n",
       "      <td>-0.023063</td>\n",
       "      <td>-0.394777</td>\n",
       "      <td>0.451383</td>\n",
       "      <td>0.316378</td>\n",
       "      <td>0.294143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012089</td>\n",
       "      <td>0.055857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StateHoliday</th>\n",
       "      <td>0.000543</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.067317</td>\n",
       "      <td>-0.004752</td>\n",
       "      <td>-0.053762</td>\n",
       "      <td>-0.257671</td>\n",
       "      <td>-0.230050</td>\n",
       "      <td>-0.383098</td>\n",
       "      <td>-0.012089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.065093</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>-0.200570</td>\n",
       "      <td>0.076141</td>\n",
       "      <td>0.064804</td>\n",
       "      <td>0.076865</td>\n",
       "      <td>0.055857</td>\n",
       "      <td>0.156845</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Store      Week       Day  DayofYear  DayOfWeek     Sales  \\\n",
       "Store          1.000000  0.001467  0.000025   0.001510  -0.000009  0.005338   \n",
       "Week           0.001467  1.000000  0.067457   0.968224  -0.004208  0.052120   \n",
       "Day            0.000025  0.067457  1.000000   0.097123   0.006992 -0.014450   \n",
       "DayofYear      0.001510  0.968224  0.097123   1.000000  -0.004873  0.046971   \n",
       "DayOfWeek     -0.000009 -0.004208  0.006992  -0.004873   1.000000 -0.461249   \n",
       "Sales          0.005338  0.052120 -0.014450   0.046971  -0.461249  1.000000   \n",
       "Customers      0.024410  0.041524 -0.005487   0.037935  -0.386213  0.895700   \n",
       "Open          -0.000030  0.002938  0.033735   0.000974  -0.527372  0.679248   \n",
       "Promo          0.000064 -0.001098 -0.117171  -0.023063  -0.394777  0.451383   \n",
       "StateHoliday   0.000543 -0.000328 -0.067317  -0.004752  -0.053762 -0.257671   \n",
       "SchoolHoliday -0.000066  0.065093  0.014925   0.100981  -0.200570  0.076141   \n",
       "\n",
       "               Customers      Open     Promo  StateHoliday  SchoolHoliday  \n",
       "Store           0.024410 -0.000030  0.000064      0.000543      -0.000066  \n",
       "Week            0.041524  0.002938 -0.001098     -0.000328       0.065093  \n",
       "Day            -0.005487  0.033735 -0.117171     -0.067317       0.014925  \n",
       "DayofYear       0.037935  0.000974 -0.023063     -0.004752       0.100981  \n",
       "DayOfWeek      -0.386213 -0.527372 -0.394777     -0.053762      -0.200570  \n",
       "Sales           0.895700  0.679248  0.451383     -0.257671       0.076141  \n",
       "Customers       1.000000  0.618407  0.316378     -0.230050       0.064804  \n",
       "Open            0.618407  1.000000  0.294143     -0.383098       0.076865  \n",
       "Promo           0.316378  0.294143  1.000000     -0.012089       0.055857  \n",
       "StateHoliday   -0.230050 -0.383098 -0.012089      1.000000       0.156845  \n",
       "SchoolHoliday   0.064804  0.076865  0.055857      0.156845       1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets apply correlation analysis to sekect the best features\n",
    "traindata.corr()\n",
    "#from below correlation results it seems that The best fetures wrt to 'Sales' are :\n",
    "# Customers(89% corr), Open(68% corr), DayOfWeek(-46% corr ),Promo(45% corr), StateHoliday(-25% corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLUMN_NAMES = [\"Approach\",\"Model_Name\",\"r2_Scores\",\"RMSE\",\"MAE\"]\n",
    "df_model_selection = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "def model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test):\n",
    "    global df_model_selection\n",
    "     \n",
    "    r2score =0\n",
    "    RMSE =0\n",
    "    MAE = 0\n",
    "    #print('Approach is: ',approach)\n",
    "    #if ((approach != 'Model Training with PCA')|(approach !='Model Training with  Kernel PCA')|(approach != 'LSTM')):\n",
    "        # Standaradization of Data\n",
    "        #SC=StandardScaler()\n",
    "        #X_train=SC.fit_transform(X_train) # Perform feature scaling on train data\n",
    "        #X_test=SC.fit_transform(X_test) # Perform feature scaling on test data\n",
    "    #else:\n",
    "        #print('Standard SCaling is performed on Train and Test Data')\n",
    "    \n",
    "    if model_name=='LSTM':\n",
    "        model_obj.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=150,batch_size=32,verbose=0)\n",
    "    else:\n",
    "        model_obj.fit(X_train, y_train)\n",
    "        \n",
    "    test_ds_predicted = model_obj.predict( X_test )\n",
    "    r2score=round(r2_score(y_true=y_test, y_pred=test_ds_predicted),2)\n",
    "    RMSE=round(np.sqrt(mean_squared_error(y_true=y_test, y_pred=test_ds_predicted)),0)\n",
    "    MAE=round(mean_absolute_error(y_true=y_test, y_pred=test_ds_predicted),2)\n",
    "    \n",
    "    df_model_selection = pd.concat([df_model_selection,pd.DataFrame([[approach,\n",
    "                                                                      model_name,\n",
    "                                                                      r2score,\n",
    "                                                                      RMSE,\n",
    "                                                                      MAE\n",
    "                                                                     ]], \n",
    "                                                                    columns =COLUMN_NAMES)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = [\"Approach\",\"Model Name\", \n",
    "                \"r2 Scores\",\"Range of r2 Scores\",\"SD of r2 Scores\",\n",
    "                \"RMSE\",\"Range of RMSE\",\n",
    "                \"MAE\",\"Range of MAE\"\n",
    "               ]\n",
    "df_model_selection = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "def model_traintest_CV(model_obj, model_name, approach,X,y,n_splits):\n",
    "    global df_model_selection\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits, random_state=12,shuffle=True)\n",
    "    \n",
    "    weighted_r2_score = []\n",
    "    weighted_RMSE = []\n",
    "    weighted_MAE = []\n",
    "     \n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index] \n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if ((model_name=='LSTM')|(model_name=='ANN')):\n",
    "            model_obj.fit(X_train,y_train,epochs=150,batch_size=32,verbose=0)\n",
    "            #model_obj.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=150,batch_size=32,verbose=0)\n",
    "        else:\n",
    "            model_obj.fit(X_train, y_train)\n",
    "        \n",
    "        test_ds_predicted = model_obj.predict( X_test )   \n",
    "        weighted_r2_score.append(round(r2_score(y_true=y_test, y_pred=test_ds_predicted),2))\n",
    "        weighted_RMSE.append(round(np.sqrt(mean_squared_error(y_true=y_test, y_pred=test_ds_predicted)),0))\n",
    "        weighted_MAE.append(round(mean_absolute_error(y_true=y_test, y_pred=test_ds_predicted),2))\n",
    "     \n",
    "    #r2_score computation\n",
    "    sd_weighted_r2_score = round(np.std(weighted_r2_score, ddof=1),2)\n",
    "    range_of_r2_scores = \"{}-{}\".format(min(weighted_r2_score),max(weighted_r2_score)) \n",
    "    \n",
    "    \n",
    "    #RMSE computation\n",
    "    #sd_weighted_RMSE = round(np.std(weighted_RMSE, ddof=1),2)\n",
    "    range_of_RMSE = \"{}-{}\".format(min(weighted_RMSE),max(weighted_RMSE))\n",
    "    \n",
    "    #MAE computation\n",
    "    #sd_weighted_MAE = round(np.std(weighted_MAE, ddof=1),2)\n",
    "    range_of_MAE = \"{}-{}\".format(min(weighted_MAE),max(weighted_MAE))\n",
    "    \n",
    "    df_model_selection = pd.concat([df_model_selection,pd.DataFrame([[approach,\n",
    "                                                                      model_name,\n",
    "                                                                      sorted(weighted_r2_score),\n",
    "                                                                      range_of_r2_scores,\n",
    "                                                                      sd_weighted_r2_score,\n",
    "                                                                      sorted(weighted_RMSE),\n",
    "                                                                      range_of_RMSE,                                                        \n",
    "                                                                      sorted(weighted_MAE),\n",
    "                                                                      range_of_MAE#,                                                                     \n",
    "                                                                     ]], \n",
    "                                                                    columns =COLUMN_NAMES)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Training with Cross Validation\n",
    "    a.Train a single model for 10 stores\n",
    "    b. Train separate models for each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.14 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.98, 544.84, 548.33, 548.55, 553.99]</td>\n",
       "      <td>538.98-553.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 414.0]</td>\n",
       "      <td>382.0-414.0</td>\n",
       "      <td>[265.91, 272.55, 272.71, 273.94, 276.64]</td>\n",
       "      <td>265.91-276.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Approach  \\\n",
       "0  Model Training with  10 Stores Data   \n",
       "0      Model Training with Store1 Data   \n",
       "0      Model Training with Store2 Data   \n",
       "0      Model Training with Store3 Data   \n",
       "0      Model Training with Store4 Data   \n",
       "0      Model Training with Store5 Data   \n",
       "0      Model Training with Store6 Data   \n",
       "0      Model Training with Store7 Data   \n",
       "0      Model Training with Store8 Data   \n",
       "0      Model Training with Store9 Data   \n",
       "0     Model Training with Store10 Data   \n",
       "0  Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data   \n",
       "0                    Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                 RMSE  \\\n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00  [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01  [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01  [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00  [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01  [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00  [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00  [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00  [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00  [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00  [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01  [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00  [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01  [382.0, 387.0, 390.0, 396.0, 414.0]   \n",
       "\n",
       "  Range of RMSE                                       MAE   Range of MAE  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.62, 554.01]  539.01-554.01  \n",
       "0   243.0-264.0  [189.32, 191.26, 195.81, 199.95, 204.91]  189.32-204.91  \n",
       "0   420.0-598.0     [304.21, 326.6, 333.4, 333.8, 340.42]  304.21-340.42  \n",
       "0   450.0-587.0   [348.45, 360.18, 373.76, 402.8, 404.99]  348.45-404.99  \n",
       "0   389.0-461.0   [288.51, 303.81, 304.2, 305.83, 345.36]  288.51-345.36  \n",
       "0   425.0-511.0  [322.94, 332.13, 334.76, 347.04, 353.21]  322.94-353.21  \n",
       "0   308.0-343.0   [228.1, 238.39, 251.72, 253.29, 265.95]   228.1-265.95  \n",
       "0   661.0-725.0   [479.93, 502.99, 507.38, 510.57, 515.9]   479.93-515.9  \n",
       "0   411.0-493.0  [313.53, 319.11, 344.25, 361.63, 363.62]  313.53-363.62  \n",
       "0   348.0-387.0  [248.59, 249.59, 261.29, 261.74, 261.85]  248.59-261.85  \n",
       "0   326.0-348.0  [253.24, 253.97, 254.97, 257.17, 261.38]  253.24-261.38  \n",
       "0   747.0-761.0  [538.52, 544.45, 547.65, 548.19, 553.62]  538.52-553.62  \n",
       "0   747.0-761.0  [538.98, 544.84, 548.33, 548.55, 553.99]  538.98-553.99  \n",
       "0   823.0-831.0  [584.13, 588.87, 593.47, 595.88, 603.25]  584.13-603.25  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.61, 554.01]  539.01-554.01  \n",
       "0   327.0-334.0  [224.17, 224.43, 224.75, 225.25, 229.57]  224.17-229.57  \n",
       "0   382.0-414.0  [265.91, 272.55, 272.71, 273.94, 276.64]  265.91-276.64  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Prepare Data\n",
    "\n",
    "traindata=traindata_init[traindata_init.Store.isin(storeList)]\n",
    "test_hiddata=test_hiddata_init[test_hiddata_init.Store.isin(storeList)]\n",
    "\n",
    "\n",
    "#Lets take data only for 10 stores\n",
    "X_train=traindata.drop(columns=['Sales','Date']).values\n",
    "y_train=traindata.Sales.values\n",
    "X_test=test_hiddata.drop(columns=['Sales','Date']).values\n",
    "y_test=test_hiddata.Sales.values\n",
    "\n",
    "#Lets take data only for Store-1\n",
    "X_train1=traindata[traindata.Store==1].drop(columns=['Sales','Date']).values\n",
    "y_train1=traindata[traindata.Store==1].Sales.values\n",
    "X_test1=test_hiddata[test_hiddata.Store==1].drop(columns=['Sales','Date']).values\n",
    "y_test1=test_hiddata[test_hiddata.Store==1].Sales.values\n",
    "\n",
    "#Lets take data only for Store-2\n",
    "X_train2=traindata[traindata.Store==2].drop(columns=['Sales','Date']).values\n",
    "y_train2=traindata[traindata.Store==2].Sales.values\n",
    "X_test2=test_hiddata[test_hiddata.Store==2].drop(columns=['Sales','Date']).values\n",
    "y_test2=test_hiddata[test_hiddata.Store==2].Sales.values\n",
    "\n",
    "#Lets take data only for Store-3\n",
    "X_train3=traindata[traindata.Store==3].drop(columns=['Sales','Date']).values\n",
    "y_train3=traindata[traindata.Store==3].Sales.values\n",
    "X_test3=test_hiddata[test_hiddata.Store==3].drop(columns=['Sales','Date']).values\n",
    "y_test3=test_hiddata[test_hiddata.Store==3].Sales.values\n",
    "\n",
    "#Lets take data only for Store-4\n",
    "X_train4=traindata[traindata.Store==4].drop(columns=['Sales','Date']).values\n",
    "y_train4=traindata[traindata.Store==4].Sales.values\n",
    "X_test4=test_hiddata[test_hiddata.Store==4].drop(columns=['Sales','Date']).values\n",
    "y_test4=test_hiddata[test_hiddata.Store==4].Sales.values\n",
    "\n",
    "#Lets take data only for Store-5\n",
    "X_train5=traindata[traindata.Store==5].drop(columns=['Sales','Date']).values\n",
    "y_train5=traindata[traindata.Store==5].Sales.values\n",
    "X_test5=test_hiddata[test_hiddata.Store==5].drop(columns=['Sales','Date']).values\n",
    "y_test5=test_hiddata[test_hiddata.Store==5].Sales.values\n",
    "\n",
    "#Lets take data only for Store-6\n",
    "X_train6=traindata[traindata.Store==6].drop(columns=['Sales','Date']).values\n",
    "y_train6=traindata[traindata.Store==6].Sales.values\n",
    "X_test6=test_hiddata[test_hiddata.Store==6].drop(columns=['Sales','Date']).values\n",
    "y_test6=test_hiddata[test_hiddata.Store==6].Sales.values\n",
    "\n",
    "#Lets take data only for Store-7\n",
    "X_train7=traindata[traindata.Store==7].drop(columns=['Sales','Date']).values\n",
    "y_train7=traindata[traindata.Store==7].Sales.values\n",
    "X_test7=test_hiddata[test_hiddata.Store==7].drop(columns=['Sales','Date']).values\n",
    "y_test7=test_hiddata[test_hiddata.Store==7].Sales.values\n",
    "\n",
    "#Lets take data only for Store-8\n",
    "X_train8=traindata[traindata.Store==8].drop(columns=['Sales','Date']).values\n",
    "y_train8=traindata[traindata.Store==8].Sales.values\n",
    "X_test8=test_hiddata[test_hiddata.Store==8].drop(columns=['Sales','Date']).values\n",
    "y_test8=test_hiddata[test_hiddata.Store==8].Sales.values\n",
    "\n",
    "#Lets take data only for Store-9\n",
    "X_train9=traindata[traindata.Store==9].drop(columns=['Sales','Date']).values\n",
    "y_train9=traindata[traindata.Store==9].Sales.values\n",
    "X_test9=test_hiddata[test_hiddata.Store==9].drop(columns=['Sales','Date']).values\n",
    "y_test9=test_hiddata[test_hiddata.Store==9].Sales.values\n",
    "\n",
    "#Lets take data only for Store-10\n",
    "X_train10=traindata[traindata.Store==10].drop(columns=['Sales','Date']).values\n",
    "y_train10=traindata[traindata.Store==10].Sales.values\n",
    "X_test10=test_hiddata[test_hiddata.Store==10].drop(columns=['Sales','Date']).values\n",
    "y_test10=test_hiddata[test_hiddata.Store==10].Sales.values\n",
    "\n",
    "\n",
    "#COLUMN_NAMES = [\"Approach\",\"Model_Name\",\"r2_Scores\",\"RMSE\",\"MAE\"]\n",
    "COLUMN_NAMES = [\"Approach\",\"Model Name\",\"r2 Scores\",\"Range of r2 Scores\",\n",
    "                \"SD of r2 Scores\",\"RMSE\",\"Range of RMSE\",\"MAE\",\"Range of MAE\"]\n",
    "df_model_selection = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "\n",
    "# 1.LinearRegression for  10 stores\n",
    "approach='Model Training with  10 Stores Data'\n",
    "X_train = X_train\n",
    "y_train = y_train\n",
    "X_test = X_test\n",
    "y_test = y_test\n",
    "model_LR=LinearRegression()\n",
    "model_obj=model_LR\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 2.LinearRegression for  store1\n",
    "approach='Model Training with Store1 Data'\n",
    "X_train = X_train1\n",
    "y_train = y_train1\n",
    "X_test = X_test1\n",
    "y_test = y_test1\n",
    "model_LR1=LinearRegression()\n",
    "model_obj=model_LR1\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 3.LinearRegression for  store2\n",
    "approach='Model Training with Store2 Data'\n",
    "X_train = X_train2\n",
    "y_train = y_train2\n",
    "X_test = X_test2\n",
    "y_test = y_test2\n",
    "model_LR2=LinearRegression()\n",
    "model_obj=model_LR2\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 4.LinearRegression for  store3\n",
    "approach='Model Training with Store3 Data'\n",
    "X_train = X_train3\n",
    "y_train = y_train3\n",
    "X_test = X_test3\n",
    "y_test = y_test3\n",
    "model_LR3=LinearRegression()\n",
    "model_obj=model_LR3\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 5.LinearRegression for  store4\n",
    "approach='Model Training with Store4 Data'\n",
    "X_train = X_train4\n",
    "y_train = y_train4\n",
    "X_test = X_test4\n",
    "y_test = y_test4\n",
    "model_LR4=LinearRegression()\n",
    "model_obj=model_LR4\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 6.LinearRegression for  store5\n",
    "approach='Model Training with Store5 Data'\n",
    "X_train = X_train5\n",
    "y_train = y_train5\n",
    "X_test = X_test5\n",
    "y_test = y_test5\n",
    "model_LR5=LinearRegression()\n",
    "model_obj=model_LR5\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 7.LinearRegression for  store6\n",
    "approach='Model Training with Store6 Data'\n",
    "X_train = X_train6\n",
    "y_train = y_train6\n",
    "X_test = X_test6\n",
    "y_test = y_test6\n",
    "model_LR6=LinearRegression()\n",
    "model_obj=model_LR6\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 8.LinearRegression for  store7\n",
    "approach='Model Training with Store7 Data'\n",
    "X_train = X_train7\n",
    "y_train = y_train7\n",
    "X_test = X_test7\n",
    "y_test = y_test7\n",
    "model_LR7=LinearRegression()\n",
    "model_obj=model_LR7\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 9.LinearRegression for  store8\n",
    "approach='Model Training with Store8 Data'\n",
    "X_train = X_train8\n",
    "y_train = y_train8\n",
    "X_test = X_test8\n",
    "y_test = y_test8\n",
    "model_LR8=LinearRegression()\n",
    "model_obj=model_LR8\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 10.LinearRegression for  store9\n",
    "approach='Model Training with Store9 Data'\n",
    "X_train = X_train9\n",
    "y_train = y_train9\n",
    "X_test = X_test9\n",
    "y_test = y_test9\n",
    "model_LR9=LinearRegression()\n",
    "model_obj=model_LR9\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 11.LinearRegression for  store10\n",
    "approach='Model Training with Store10 Data'\n",
    "X_train = X_train10\n",
    "y_train = y_train10\n",
    "X_test = X_test10\n",
    "y_test = y_test10\n",
    "model_LR10=LinearRegression()\n",
    "model_obj=model_LR10\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "######################Regularized Linear Regression Method ######################\n",
    "#Data from 10 stores\n",
    "X_train=traindata.drop(columns=['Sales','Date']).values\n",
    "y_train=traindata.Sales.values\n",
    "X_test=test_hiddata.drop(columns=['Sales','Date']).values\n",
    "y_test=test_hiddata.Sales.values\n",
    "\n",
    "# 12.Regularized Linear Regression- Lasso\n",
    "approach='Model Training with  10 Stores Data'\n",
    "model_Lasso=Lasso()\n",
    "model_obj=model_Lasso\n",
    "model_name='Regularized Linear Regression- Lasso'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "# 13.Regularized Linear Regression- Ridge\n",
    "approach='Model Training with  10 Stores Data'\n",
    "model_Ridge=Ridge()\n",
    "model_obj=model_Ridge\n",
    "model_name='Regularized Linear Regression- Ridge'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "# 14.Regularized Linear Regression- ElasticNet\n",
    "approach='Model Training with  10 Stores Data'\n",
    "model_ElasticNet=ElasticNet()\n",
    "model_obj=model_ElasticNet\n",
    "model_name='Regularized Linear Regression- ElasticNet'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "#########################################################################\n",
    "####################Ensemble Learning####################################\n",
    "########################################################################\n",
    "\n",
    "# 15.Ensemble Learning\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "model_ensemble = VotingRegressor([('M10', model_LR),\n",
    "                                  ('M1',model_LR1),\n",
    "                                  ('M3',model_LR3),\n",
    "                                  ('M5',model_LR5),\n",
    "                                      ('M6',model_LR6),\n",
    "                                      ('M7',model_LR7),\n",
    "                                      ('M8',model_LR8),\n",
    "                                     ('MR',model_Ridge)\n",
    "                                      ])\n",
    "\n",
    "approach='Ensemble Learning'\n",
    "model_obj=model_ensemble\n",
    "model_name='Ensemble Learner LR+RegLR'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "######################OTHER OPEN METHODS - BOOSTING ######################\n",
    "\n",
    "# 15.Lets Use Boosting Technique(XGboost)\n",
    "approach='Model Training with  10 Stores Data'\n",
    "model_XGBR=XGBRegressor()\n",
    "model_obj=model_XGBR\n",
    "model_name='XGBoost Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 16.Lets Use Ensemble Gradiant Boosting\n",
    "approach='Model Training with  10 Stores Data'\n",
    "model_GBR=GradientBoostingRegressor()\n",
    "model_obj=model_GBR\n",
    "model_name='Gradiant Boosting Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "#Exporting the results to csv\n",
    "#df_model_selection.to_csv(\"Model_statistics-week1.csv\",index = False)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation!!! \n",
    "**Summary of Model Testing and Evaluation at end of Week-2**\n",
    "\n",
    "\n",
    "    1.The performance of single store model seems to be outperformed for some stores than the combined 10stores model.\n",
    "    2.Use of Regularized regression did not have much impact to the overall performance.\n",
    "    3.Boosting method such as XGBoost and  GradientBoosting seems to perform better then Linear Regression model.\n",
    "    4.Ensemble method performance is also good but not much of a difference from individual Learner in this use case. \n",
    "    5.Among all accuracy matrices , R2 score is more meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 2\n",
    "\n",
    "**Other Regression Techniques:**\n",
    "\n",
    "1. When store is closed, sales = 0. Can this insight be used for Data Cleaning? Perform this and retrain the model. Any benefits of this step?\n",
    "2. Use Non-Linear Regressors like Random Forest or other Tree-based Regressors. \n",
    "   \n",
    "   a) Train a single model for all stores, where storeId can be a feature.\n",
    "   \n",
    "   b) Train separate model for each store.\n",
    "   \n",
    "   **Note:** Dimensional Reduction techniques like, PCA and Trees Hyperparameter Tuning will be required. Cross-validate        to  find the best parameters. Infer the performance of both the models\n",
    "\n",
    "3. Compare the performance of Linear Model and Non-Linear Model from the previous observations. Which performs better and why?\n",
    "\n",
    "4. Train a Time-series model on the data taking time as the only feature. This will be a store-level training.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.33 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.98, 544.84, 548.33, 548.55, 553.99]</td>\n",
       "      <td>538.98-553.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 414.0]</td>\n",
       "      <td>382.0-414.0</td>\n",
       "      <td>[265.91, 272.55, 272.71, 273.94, 276.64]</td>\n",
       "      <td>265.91-276.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.49, 603.64, 604.49, 606.82, 612.89]</td>\n",
       "      <td>599.49-612.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 412.0, 416.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.69, 303.43, 303.9, 304.32, 308.96]</td>\n",
       "      <td>292.69-308.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                 RMSE  \\\n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00  [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01  [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01  [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00  [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01  [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00  [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00  [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00  [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00  [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00  [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01  [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00  [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01  [382.0, 387.0, 390.0, 396.0, 414.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.85-0.87             0.01  [863.0, 877.0, 878.0, 879.0, 886.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.98-0.98             0.00  [351.0, 356.0, 361.0, 365.0, 369.0]   \n",
       "0          0.97-0.97             0.00  [403.0, 412.0, 416.0, 431.0, 435.0]   \n",
       "\n",
       "  Range of RMSE                                       MAE   Range of MAE  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.62, 554.01]  539.01-554.01  \n",
       "0   243.0-264.0  [189.32, 191.26, 195.81, 199.95, 204.91]  189.32-204.91  \n",
       "0   420.0-598.0     [304.21, 326.6, 333.4, 333.8, 340.42]  304.21-340.42  \n",
       "0   450.0-587.0   [348.45, 360.18, 373.76, 402.8, 404.99]  348.45-404.99  \n",
       "0   389.0-461.0   [288.51, 303.81, 304.2, 305.83, 345.36]  288.51-345.36  \n",
       "0   425.0-511.0  [322.94, 332.13, 334.76, 347.04, 353.21]  322.94-353.21  \n",
       "0   308.0-343.0   [228.1, 238.39, 251.72, 253.29, 265.95]   228.1-265.95  \n",
       "0   661.0-725.0   [479.93, 502.99, 507.38, 510.57, 515.9]   479.93-515.9  \n",
       "0   411.0-493.0  [313.53, 319.11, 344.25, 361.63, 363.62]  313.53-363.62  \n",
       "0   348.0-387.0  [248.59, 249.59, 261.29, 261.74, 261.85]  248.59-261.85  \n",
       "0   326.0-348.0  [253.24, 253.97, 254.97, 257.17, 261.38]  253.24-261.38  \n",
       "0   747.0-761.0  [538.52, 544.45, 547.65, 548.19, 553.62]  538.52-553.62  \n",
       "0   747.0-761.0  [538.98, 544.84, 548.33, 548.55, 553.99]  538.98-553.99  \n",
       "0   823.0-831.0  [584.13, 588.87, 593.47, 595.88, 603.25]  584.13-603.25  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.61, 554.01]  539.01-554.01  \n",
       "0   327.0-334.0  [224.17, 224.43, 224.75, 225.25, 229.57]  224.17-229.57  \n",
       "0   382.0-414.0  [265.91, 272.55, 272.71, 273.94, 276.64]  265.91-276.64  \n",
       "0   806.0-817.0  [599.65, 603.74, 604.48, 606.87, 612.88]  599.65-612.88  \n",
       "0   806.0-818.0  [599.67, 604.08, 604.57, 606.86, 613.25]  599.67-613.25  \n",
       "0   806.0-817.0  [599.49, 603.64, 604.49, 606.82, 612.89]  599.49-612.89  \n",
       "0   863.0-886.0  [638.17, 643.96, 646.54, 646.91, 668.87]  638.17-668.87  \n",
       "0   806.0-817.0  [599.57, 603.69, 604.48, 606.85, 612.88]  599.57-612.88  \n",
       "0   351.0-369.0   [264.28, 264.31, 264.82, 267.54, 272.7]   264.28-272.7  \n",
       "0   403.0-435.0   [292.69, 303.43, 303.9, 304.32, 308.96]  292.69-308.96  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Prepare Data\n",
    "traindata=traindata_init[(traindata_init.Sales !=0)&(traindata_init.Store.isin(storeList))]\n",
    "test_hiddata=test_hiddata_init[(test_hiddata_init.Sales !=0)&(test_hiddata_init.Store.isin(storeList))]\n",
    "\n",
    "\n",
    "#Lets take data only for 10 stores\n",
    "X_train=traindata.drop(columns=['Sales','Date']).values\n",
    "y_train=traindata.Sales.values\n",
    "X_test=test_hiddata.drop(columns=['Sales','Date']).values\n",
    "y_test=test_hiddata.Sales.values\n",
    "\n",
    "\n",
    "# 1.LinearRegression for  10 stores\n",
    "approach='Model Training with  10 Stores Data with Open Days '\n",
    "X_train = X_train\n",
    "y_train = y_train\n",
    "X_test = X_test\n",
    "y_test = y_test\n",
    "model_LR=LinearRegression()\n",
    "model_obj=model_LR\n",
    "model_name='Linear Regression'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "\n",
    "######################Regularized Linear Regression Method ######################\n",
    "#Data from 10 stores\n",
    "X_train=traindata.drop(columns=['Sales','Date']).values\n",
    "y_train=traindata.Sales.values\n",
    "X_test=test_hiddata.drop(columns=['Sales','Date']).values\n",
    "y_test=test_hiddata.Sales.values\n",
    "\n",
    "# 12.Regularized Linear Regression- Lasso\n",
    "approach='Model Training with  10 Stores Data with Open Days'\n",
    "model_Lasso=Lasso()\n",
    "model_obj=model_Lasso\n",
    "model_name='Regularized Linear Regression- Lasso'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "# 13.Regularized Linear Regression- Ridge\n",
    "approach='Model Training with  10 Stores Data with Open Days'\n",
    "model_Ridge=Ridge()\n",
    "model_obj=model_Ridge\n",
    "model_name='Regularized Linear Regression- Ridge'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "# 14.Regularized Linear Regression- ElasticNet\n",
    "approach='Model Training with  10 Stores Data with Open Days'\n",
    "model_ElasticNet=ElasticNet()\n",
    "model_obj=model_ElasticNet\n",
    "model_name='Regularized Linear Regression- ElasticNet'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "#########################################################################\n",
    "####################Ensemble Learning####################################\n",
    "########################################################################\n",
    "\n",
    "# 15.Ensemble Learning\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "model_ensemble = VotingRegressor([('M10', model_LR),\n",
    "                                     ('MR',model_Ridge)\n",
    "                                      ])\n",
    "\n",
    "approach='Ensemble Learning'\n",
    "model_obj=model_ensemble\n",
    "model_name='Ensemble Learner LR+RegLR'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "######################OTHER OPEN METHODS - BOOSTING ######################\n",
    "\n",
    "# 15.Lets Use Boosting Technique(XGboost)\n",
    "approach='Model Training with  10 Stores Data with Open Days'\n",
    "model_XGBR=XGBRegressor()\n",
    "model_obj=model_XGBR\n",
    "model_name='XGBoost Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "# 16.Lets Use Ensemble Gradiant Boosting\n",
    "approach='Model Training with  10 Stores Data with Open Days'\n",
    "model_GBR=GradientBoostingRegressor()\n",
    "model_obj=model_GBR\n",
    "model_name='Gradiant Boosting Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "#Exporting the results to csv\n",
    "#df_model_selection.to_csv(\"Model_statistics-week1.csv\",index = False)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: From above test results it is evident that\n",
    "    Removing zero sales days from the dataset have negative impact on the overall performance. \n",
    "    r2 score of the test models have been reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Week 2 Tasks -2 \n",
    "#1.Use Non-Linear Regressors like Decesion Tree,Random Forest \n",
    "#2.Apply Dimensional Reduction techniques like, PCA to extract the best features\n",
    "#3.Hyperparameter tuning to find the best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayofYear</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106</td>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980420</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>6089</td>\n",
       "      <td>781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980421</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>8244</td>\n",
       "      <td>955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980422</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>5419</td>\n",
       "      <td>698</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980423</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4903</td>\n",
       "      <td>481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980424</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4812</td>\n",
       "      <td>521</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7550 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  Week  Day  DayofYear  DayOfWeek       Date  Sales  Customers  \\\n",
       "0           1    27   30        181          2 2015-06-30   5735        568   \n",
       "1           2    27   30        181          2 2015-06-30   9863        877   \n",
       "2           3    27   30        181          2 2015-06-30  13261       1072   \n",
       "3           4    27   30        181          2 2015-06-30  13106       1488   \n",
       "4           5    27   30        181          2 2015-06-30   6635        645   \n",
       "...       ...   ...  ...        ...        ...        ...    ...        ...   \n",
       "980420      6     1    2          2          3 2013-01-02   6089        781   \n",
       "980421      7     1    2          2          3 2013-01-02   8244        955   \n",
       "980422      8     1    2          2          3 2013-01-02   5419        698   \n",
       "980423      9     1    2          2          3 2013-01-02   4903        481   \n",
       "980424     10     1    2          2          3 2013-01-02   4812        521   \n",
       "\n",
       "        Open  Promo  StateHoliday  SchoolHoliday  \n",
       "0          1      1             0              0  \n",
       "1          1      1             0              0  \n",
       "2          1      1             0              1  \n",
       "3          1      1             0              0  \n",
       "4          1      1             0              0  \n",
       "...      ...    ...           ...            ...  \n",
       "980420     1      0             0              1  \n",
       "980421     1      0             0              1  \n",
       "980422     1      0             0              1  \n",
       "980423     1      0             0              1  \n",
       "980424     1      0             0              1  \n",
       "\n",
       "[7550 rows x 12 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained Variance Ratio is [0.22190875 0.39717907 0.51632957 0.62915453 0.73868265 0.84119551\n",
      " 0.9229533  0.99572068 1.         1.        ]\n",
      "Wall time: 26.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.98, 544.84, 548.33, 548.55, 553.99]</td>\n",
       "      <td>538.98-553.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 414.0]</td>\n",
       "      <td>382.0-414.0</td>\n",
       "      <td>[265.91, 272.55, 272.71, 273.94, 276.64]</td>\n",
       "      <td>265.91-276.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.49, 603.64, 604.49, 606.82, 612.89]</td>\n",
       "      <td>599.49-612.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 412.0, 416.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.69, 303.43, 303.9, 304.32, 308.96]</td>\n",
       "      <td>292.69-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.85, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[884.0, 888.0, 915.0, 934.0, 955.0]</td>\n",
       "      <td>884.0-955.0</td>\n",
       "      <td>[635.32, 642.37, 646.2, 674.9, 677.73]</td>\n",
       "      <td>635.32-677.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[603.0, 614.0, 624.0, 633.0, 651.0]</td>\n",
       "      <td>603.0-651.0</td>\n",
       "      <td>[442.6, 454.42, 464.43, 465.87, 466.84]</td>\n",
       "      <td>442.6-466.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.85, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[890.0, 895.0, 913.0, 934.0, 969.0]</td>\n",
       "      <td>890.0-969.0</td>\n",
       "      <td>[643.25, 646.42, 648.33, 675.59, 691.2]</td>\n",
       "      <td>643.25-691.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[602.0, 614.0, 629.0, 631.0, 646.0]</td>\n",
       "      <td>602.0-646.0</td>\n",
       "      <td>[442.4, 452.21, 461.28, 465.87, 467.84]</td>\n",
       "      <td>442.4-467.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.85, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.85, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                 RMSE  \\\n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00  [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01  [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01  [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00  [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01  [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00  [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00  [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00  [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00  [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00  [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01  [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00  [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01  [382.0, 387.0, 390.0, 396.0, 414.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.85-0.87             0.01  [863.0, 877.0, 878.0, 879.0, 886.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.98-0.98             0.00  [351.0, 356.0, 361.0, 365.0, 369.0]   \n",
       "0          0.97-0.97             0.00  [403.0, 412.0, 416.0, 431.0, 435.0]   \n",
       "0          0.84-0.86             0.01  [884.0, 888.0, 915.0, 934.0, 955.0]   \n",
       "0          0.93-0.94             0.00  [603.0, 614.0, 624.0, 633.0, 651.0]   \n",
       "0          0.84-0.86             0.01  [890.0, 895.0, 913.0, 934.0, 969.0]   \n",
       "0          0.93-0.94             0.00  [602.0, 614.0, 629.0, 631.0, 646.0]   \n",
       "\n",
       "  Range of RMSE                                       MAE   Range of MAE  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.62, 554.01]  539.01-554.01  \n",
       "0   243.0-264.0  [189.32, 191.26, 195.81, 199.95, 204.91]  189.32-204.91  \n",
       "0   420.0-598.0     [304.21, 326.6, 333.4, 333.8, 340.42]  304.21-340.42  \n",
       "0   450.0-587.0   [348.45, 360.18, 373.76, 402.8, 404.99]  348.45-404.99  \n",
       "0   389.0-461.0   [288.51, 303.81, 304.2, 305.83, 345.36]  288.51-345.36  \n",
       "0   425.0-511.0  [322.94, 332.13, 334.76, 347.04, 353.21]  322.94-353.21  \n",
       "0   308.0-343.0   [228.1, 238.39, 251.72, 253.29, 265.95]   228.1-265.95  \n",
       "0   661.0-725.0   [479.93, 502.99, 507.38, 510.57, 515.9]   479.93-515.9  \n",
       "0   411.0-493.0  [313.53, 319.11, 344.25, 361.63, 363.62]  313.53-363.62  \n",
       "0   348.0-387.0  [248.59, 249.59, 261.29, 261.74, 261.85]  248.59-261.85  \n",
       "0   326.0-348.0  [253.24, 253.97, 254.97, 257.17, 261.38]  253.24-261.38  \n",
       "0   747.0-761.0  [538.52, 544.45, 547.65, 548.19, 553.62]  538.52-553.62  \n",
       "0   747.0-761.0  [538.98, 544.84, 548.33, 548.55, 553.99]  538.98-553.99  \n",
       "0   823.0-831.0  [584.13, 588.87, 593.47, 595.88, 603.25]  584.13-603.25  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.61, 554.01]  539.01-554.01  \n",
       "0   327.0-334.0  [224.17, 224.43, 224.75, 225.25, 229.57]  224.17-229.57  \n",
       "0   382.0-414.0  [265.91, 272.55, 272.71, 273.94, 276.64]  265.91-276.64  \n",
       "0   806.0-817.0  [599.65, 603.74, 604.48, 606.87, 612.88]  599.65-612.88  \n",
       "0   806.0-818.0  [599.67, 604.08, 604.57, 606.86, 613.25]  599.67-613.25  \n",
       "0   806.0-817.0  [599.49, 603.64, 604.49, 606.82, 612.89]  599.49-612.89  \n",
       "0   863.0-886.0  [638.17, 643.96, 646.54, 646.91, 668.87]  638.17-668.87  \n",
       "0   806.0-817.0  [599.57, 603.69, 604.48, 606.85, 612.88]  599.57-612.88  \n",
       "0   351.0-369.0   [264.28, 264.31, 264.82, 267.54, 272.7]   264.28-272.7  \n",
       "0   403.0-435.0   [292.69, 303.43, 303.9, 304.32, 308.96]  292.69-308.96  \n",
       "0   884.0-955.0    [635.32, 642.37, 646.2, 674.9, 677.73]  635.32-677.73  \n",
       "0   603.0-651.0   [442.6, 454.42, 464.43, 465.87, 466.84]   442.6-466.84  \n",
       "0   890.0-969.0   [643.25, 646.42, 648.33, 675.59, 691.2]   643.25-691.2  \n",
       "0   602.0-646.0   [442.4, 452.21, 461.28, 465.87, 467.84]   442.4-467.84  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Prepare data for PCA\n",
    "traindata=traindata_init[(traindata_init.Sales !=0)&(traindata_init.Store.isin(storeList))]\n",
    "traindata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "test_hiddata=test_hiddata_init[(test_hiddata_init.Sales !=0)&(test_hiddata_init.Store.isin(storeList))]\n",
    "test_hiddata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "X_train=traindata.drop(columns=['Sales','Date']).values\n",
    "X_test=test_hiddata.drop(columns=['Sales','Date']).values\n",
    "X_train=SC.fit_transform(X_train) # Perform feature scaling on train  data\n",
    "X_test=SC.fit_transform(X_test) # Perform feature scaling on test data\n",
    "\n",
    "y_train=traindata.Sales.values\n",
    "y_test=test_hiddata.Sales.values\n",
    "\n",
    "#print(len(X_train_pca),len(y_train), len(X_test_pca),len(y_test))\n",
    "\n",
    "model_pca=PCA(n_components=10)# Take all features initially\n",
    "X_train_pca=model_pca.fit_transform(X_train,y_train)\n",
    "print('Cumulative Explained Variance Ratio is',np.cumsum(model_pca.explained_variance_ratio_))\n",
    "\n",
    "model_pca=PCA(n_components=7)\n",
    "X_train_pca=model_pca.fit_transform(X_train,y_train)\n",
    "X_test_pca=model_pca.fit_transform(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "# lets use Tree based regressor\n",
    "# 17.Lets Use Decision Tree Regressor\n",
    "approach='Model Training with PCA'\n",
    "model_DTR=DecisionTreeRegressor()\n",
    "model_obj=model_DTR\n",
    "model_name='Decision Tree Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train_pca,y_train,X_test_pca,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train_pca,y_train,n_splits)\n",
    "df_model_selection\n",
    "\n",
    "# 18.Lets Use RandomForest Regressor\n",
    "approach='Model Training with PCA'\n",
    "model_RFR=RandomForestRegressor()\n",
    "model_obj=model_RFR\n",
    "model_name='RandomForest Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train_pca,y_train,X_test_pca,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train_pca,y_train,n_splits)\n",
    "\n",
    "\n",
    "\n",
    "# Lets try kernel_pca######################################## KERNEL PCA #################\n",
    "model_KPCA=KernelPCA(n_components=7)\n",
    "X_train_kpca=model_KPCA.fit_transform(X_train,y_train)\n",
    "X_test_kpca=model_KPCA.fit_transform(X_test,y_test)\n",
    "\n",
    "# lets use Tree based regressor\n",
    "# 19.Lets Use Decision Tree Regressor\n",
    "approach='Model Training with  Kernel PCA'\n",
    "model_DTR=DecisionTreeRegressor()\n",
    "model_obj=model_DTR\n",
    "model_name='Decision Tree Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train_kpca,y_train,X_test_kpca,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train_kpca,y_train,n_splits)\n",
    "\n",
    "# 20.Lets Use RandomForest Regressor\n",
    "approach='Model Training with  Kernel PCA'\n",
    "model_RFR=RandomForestRegressor()\n",
    "model_obj=model_RFR\n",
    "model_name='RandomForest Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train_kpca,y_train,X_test_kpca,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train_kpca,y_train,n_splits)\n",
    "\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation from PCA feature extraction is that there is a marginal increase in performance in case of Non linear model as compared to Linear model like Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Paremeter Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "                   param_distributions={'max_depth': [5, 6, 7, 8, 9, 10, 15, 20,\n",
       "                                                      30],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4],\n",
       "                                        'min_samples_split': [2, 3, 4, 5],\n",
       "                                        'n_estimators': [50, 100, 120, 150,\n",
       "                                                         200]})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Lets apply Gridsearch technique for Hyperparameter tuning on Random Forest Regressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid={\n",
    "            'n_estimators':[50,100,120,150,200],\n",
    "            'max_depth':[5,6,7,8,9,10,15,20,30],\n",
    "            'min_samples_split':[2,3,4,5],\n",
    "            'min_samples_leaf':[1,2,3,4],\n",
    "            'max_features' :['auto', 'sqrt', 'log2']\n",
    "           }\n",
    "model_RFR=RandomForestRegressor()\n",
    "RS = RandomizedSearchCV(estimator=model_RFR,param_distributions=param_grid,cv=10,n_iter=10)\n",
    "\n",
    "RS.fit(X_train,y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, min_samples_split=5)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9667579690383045"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 413.0]</td>\n",
       "      <td>382.0-413.0</td>\n",
       "      <td>[265.91, 272.71, 272.93, 273.94, 276.48]</td>\n",
       "      <td>265.91-276.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 411.0, 419.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.7, 303.9, 304.22, 304.31, 308.96]</td>\n",
       "      <td>292.7-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 912.0, 932.0, 968.0]</td>\n",
       "      <td>880.0-968.0</td>\n",
       "      <td>[632.76, 639.1, 639.86, 666.64, 686.81]</td>\n",
       "      <td>632.76-686.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 632.0, 649.0]</td>\n",
       "      <td>604.0-649.0</td>\n",
       "      <td>[445.04, 453.04, 464.57, 466.71, 467.52]</td>\n",
       "      <td>445.04-467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 909.0, 935.0, 954.0]</td>\n",
       "      <td>880.0-954.0</td>\n",
       "      <td>[636.73, 637.26, 642.49, 676.06, 676.63]</td>\n",
       "      <td>636.73-676.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 631.0, 651.0]</td>\n",
       "      <td>604.0-651.0</td>\n",
       "      <td>[444.05, 453.76, 462.01, 463.62, 467.3]</td>\n",
       "      <td>444.05-467.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[392.0, 404.0, 406.0, 432.0, 432.0]</td>\n",
       "      <td>392.0-432.0</td>\n",
       "      <td>[283.6, 292.89, 296.46, 300.2, 300.94]</td>\n",
       "      <td>283.6-300.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Random Forest Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                 RMSE  \\\n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00  [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01  [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01  [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00  [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01  [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00  [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00  [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00  [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00  [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00  [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01  [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00  [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01  [382.0, 387.0, 390.0, 396.0, 413.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.85-0.87             0.01  [863.0, 877.0, 878.0, 879.0, 886.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.98-0.98             0.00  [351.0, 356.0, 361.0, 365.0, 369.0]   \n",
       "0          0.97-0.97             0.00  [403.0, 411.0, 419.0, 431.0, 435.0]   \n",
       "0          0.84-0.86             0.01  [880.0, 885.0, 912.0, 932.0, 968.0]   \n",
       "0          0.93-0.94             0.00  [604.0, 611.0, 625.0, 632.0, 649.0]   \n",
       "0          0.84-0.86             0.01  [880.0, 885.0, 909.0, 935.0, 954.0]   \n",
       "0          0.93-0.94             0.00  [604.0, 611.0, 625.0, 631.0, 651.0]   \n",
       "0          0.97-0.97             0.00  [392.0, 404.0, 406.0, 432.0, 432.0]   \n",
       "\n",
       "  Range of RMSE                                       MAE   Range of MAE  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.62, 554.01]  539.01-554.01  \n",
       "0   243.0-264.0  [189.32, 191.26, 195.81, 199.95, 204.91]  189.32-204.91  \n",
       "0   420.0-598.0     [304.21, 326.6, 333.4, 333.8, 340.42]  304.21-340.42  \n",
       "0   450.0-587.0   [348.45, 360.18, 373.76, 402.8, 404.99]  348.45-404.99  \n",
       "0   389.0-461.0   [288.51, 303.81, 304.2, 305.83, 345.36]  288.51-345.36  \n",
       "0   425.0-511.0  [322.94, 332.13, 334.76, 347.04, 353.21]  322.94-353.21  \n",
       "0   308.0-343.0   [228.1, 238.39, 251.72, 253.29, 265.95]   228.1-265.95  \n",
       "0   661.0-725.0   [479.93, 502.99, 507.38, 510.57, 515.9]   479.93-515.9  \n",
       "0   411.0-493.0  [313.53, 319.11, 344.25, 361.63, 363.62]  313.53-363.62  \n",
       "0   348.0-387.0  [248.59, 249.59, 261.29, 261.74, 261.85]  248.59-261.85  \n",
       "0   326.0-348.0  [253.24, 253.97, 254.97, 257.17, 261.38]  253.24-261.38  \n",
       "0   747.0-761.0  [538.52, 544.45, 547.65, 548.19, 553.62]  538.52-553.62  \n",
       "0   747.0-761.0  [538.52, 544.45, 547.65, 548.19, 553.62]  538.52-553.62  \n",
       "0   823.0-831.0  [584.13, 588.87, 593.47, 595.88, 603.25]  584.13-603.25  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.61, 554.01]  539.01-554.01  \n",
       "0   327.0-334.0  [224.17, 224.43, 224.75, 225.25, 229.57]  224.17-229.57  \n",
       "0   382.0-413.0  [265.91, 272.71, 272.93, 273.94, 276.48]  265.91-276.48  \n",
       "0   806.0-817.0  [599.65, 603.74, 604.48, 606.87, 612.88]  599.65-612.88  \n",
       "0   806.0-818.0  [599.67, 604.08, 604.57, 606.86, 613.25]  599.67-613.25  \n",
       "0   806.0-818.0  [599.67, 604.08, 604.57, 606.86, 613.25]  599.67-613.25  \n",
       "0   863.0-886.0  [638.17, 643.96, 646.54, 646.91, 668.87]  638.17-668.87  \n",
       "0   806.0-817.0  [599.57, 603.69, 604.48, 606.85, 612.88]  599.57-612.88  \n",
       "0   351.0-369.0   [264.28, 264.31, 264.82, 267.54, 272.7]   264.28-272.7  \n",
       "0   403.0-435.0    [292.7, 303.9, 304.22, 304.31, 308.96]   292.7-308.96  \n",
       "0   880.0-968.0   [632.76, 639.1, 639.86, 666.64, 686.81]  632.76-686.81  \n",
       "0   604.0-649.0  [445.04, 453.04, 464.57, 466.71, 467.52]  445.04-467.52  \n",
       "0   880.0-954.0  [636.73, 637.26, 642.49, 676.06, 676.63]  636.73-676.63  \n",
       "0   604.0-651.0   [444.05, 453.76, 462.01, 463.62, 467.3]   444.05-467.3  \n",
       "0   392.0-432.0    [283.6, 292.89, 296.46, 300.2, 300.94]   283.6-300.94  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the final model after gridsearch\n",
    "\n",
    "# 24.Randorm Forest Regressor\n",
    "approach='Model Training after Hyperparameter Tuning'\n",
    "model_RFR=RandomForestRegressor(max_depth=20, min_samples_split=5)\n",
    "model_obj=model_RFR\n",
    "model_name='Random Forest Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:13:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:14:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { colsample_bynode, max_depth, max_features, min_samples_leaf, min_samples_split, num_parallel_tree, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:15:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Wall time: 1min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRFRegressor(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            obje...\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None),\n",
       "                   param_distributions={'booster': ['gbtree', 'gblinear',\n",
       "                                                    'dart'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.5, 0.9,\n",
       "                                                          1],\n",
       "                                        'max_depth': [5, 6, 7, 8, 9, 10, 15, 20,\n",
       "                                                      30],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4],\n",
       "                                        'min_samples_split': [2, 3, 4, 5],\n",
       "                                        'n_estimators': [50, 100, 120, 150,\n",
       "                                                         200]})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Lets apply Gridsearch technique for Hyperparameter tuning on XGBoost Regressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid={\n",
    "            'learning_rate':[0.05,0.1,0.5,0.9,1],\n",
    "            'booster':['gbtree','gblinear','dart'],\n",
    "            'n_estimators':[50,100,120,150,200],\n",
    "            'max_depth':[5,6,7,8,9,10,15,20,30],\n",
    "            'min_samples_split':[2,3,4,5],\n",
    "            'min_samples_leaf':[1,2,3,4],\n",
    "            'max_features' :['auto', 'sqrt', 'log2']\n",
    "           }\n",
    "model_XGBRFR=XGBRFRegressor()\n",
    "RS = RandomizedSearchCV(estimator=model_XGBRFR,param_distributions=param_grid,cv=10,n_iter=10)\n",
    "\n",
    "RS.fit(X_train,y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9677237197184988"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRFRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bytree=1, gamma=0, gpu_id=-1, importance_type='gain',\n",
       "               interaction_constraints='', max_delta_step=0, max_depth=15,\n",
       "               max_features='auto', min_child_weight=1, min_samples_leaf=3,\n",
       "               min_samples_split=2, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=120, n_jobs=0, num_parallel_tree=120,\n",
       "               objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "               scale_pos_weight=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:28:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:28:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:28:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:28:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:28:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_features, min_samples_leaf, min_samples_split } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 413.0]</td>\n",
       "      <td>382.0-413.0</td>\n",
       "      <td>[265.91, 272.71, 272.93, 273.94, 276.48]</td>\n",
       "      <td>265.91-276.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 411.0, 419.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.7, 303.9, 304.22, 304.31, 308.96]</td>\n",
       "      <td>292.7-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 912.0, 932.0, 968.0]</td>\n",
       "      <td>880.0-968.0</td>\n",
       "      <td>[632.76, 639.1, 639.86, 666.64, 686.81]</td>\n",
       "      <td>632.76-686.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 632.0, 649.0]</td>\n",
       "      <td>604.0-649.0</td>\n",
       "      <td>[445.04, 453.04, 464.57, 466.71, 467.52]</td>\n",
       "      <td>445.04-467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 909.0, 935.0, 954.0]</td>\n",
       "      <td>880.0-954.0</td>\n",
       "      <td>[636.73, 637.26, 642.49, 676.06, 676.63]</td>\n",
       "      <td>636.73-676.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 631.0, 651.0]</td>\n",
       "      <td>604.0-651.0</td>\n",
       "      <td>[444.05, 453.76, 462.01, 463.62, 467.3]</td>\n",
       "      <td>444.05-467.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[392.0, 404.0, 406.0, 432.0, 432.0]</td>\n",
       "      <td>392.0-432.0</td>\n",
       "      <td>[283.6, 292.89, 296.46, 300.2, 300.94]</td>\n",
       "      <td>283.6-300.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>XGBoost RFRegressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[387.0, 400.0, 406.0, 420.0, 423.0]</td>\n",
       "      <td>387.0-423.0</td>\n",
       "      <td>[283.04, 293.27, 295.01, 299.56, 303.83]</td>\n",
       "      <td>283.04-303.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Random Forest Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                        XGBoost RFRegressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                 RMSE  \\\n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00  [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01  [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01  [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00  [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01  [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00  [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00  [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00  [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00  [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00  [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01  [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01  [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00  [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01  [382.0, 387.0, 390.0, 396.0, 413.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.85-0.87             0.01  [863.0, 877.0, 878.0, 879.0, 886.0]   \n",
       "0          0.88-0.89             0.01  [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.98-0.98             0.00  [351.0, 356.0, 361.0, 365.0, 369.0]   \n",
       "0          0.97-0.97             0.00  [403.0, 411.0, 419.0, 431.0, 435.0]   \n",
       "0          0.84-0.86             0.01  [880.0, 885.0, 912.0, 932.0, 968.0]   \n",
       "0          0.93-0.94             0.00  [604.0, 611.0, 625.0, 632.0, 649.0]   \n",
       "0          0.84-0.86             0.01  [880.0, 885.0, 909.0, 935.0, 954.0]   \n",
       "0          0.93-0.94             0.00  [604.0, 611.0, 625.0, 631.0, 651.0]   \n",
       "0          0.97-0.97             0.00  [392.0, 404.0, 406.0, 432.0, 432.0]   \n",
       "0          0.97-0.97             0.00  [387.0, 400.0, 406.0, 420.0, 423.0]   \n",
       "\n",
       "  Range of RMSE                                       MAE   Range of MAE  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.62, 554.01]  539.01-554.01  \n",
       "0   243.0-264.0  [189.32, 191.26, 195.81, 199.95, 204.91]  189.32-204.91  \n",
       "0   420.0-598.0     [304.21, 326.6, 333.4, 333.8, 340.42]  304.21-340.42  \n",
       "0   450.0-587.0   [348.45, 360.18, 373.76, 402.8, 404.99]  348.45-404.99  \n",
       "0   389.0-461.0   [288.51, 303.81, 304.2, 305.83, 345.36]  288.51-345.36  \n",
       "0   425.0-511.0  [322.94, 332.13, 334.76, 347.04, 353.21]  322.94-353.21  \n",
       "0   308.0-343.0   [228.1, 238.39, 251.72, 253.29, 265.95]   228.1-265.95  \n",
       "0   661.0-725.0   [479.93, 502.99, 507.38, 510.57, 515.9]   479.93-515.9  \n",
       "0   411.0-493.0  [313.53, 319.11, 344.25, 361.63, 363.62]  313.53-363.62  \n",
       "0   348.0-387.0  [248.59, 249.59, 261.29, 261.74, 261.85]  248.59-261.85  \n",
       "0   326.0-348.0  [253.24, 253.97, 254.97, 257.17, 261.38]  253.24-261.38  \n",
       "0   747.0-761.0  [538.52, 544.45, 547.65, 548.19, 553.62]  538.52-553.62  \n",
       "0   747.0-761.0  [538.52, 544.45, 547.65, 548.19, 553.62]  538.52-553.62  \n",
       "0   823.0-831.0  [584.13, 588.87, 593.47, 595.88, 603.25]  584.13-603.25  \n",
       "0   747.0-761.0  [539.01, 544.88, 548.35, 548.61, 554.01]  539.01-554.01  \n",
       "0   327.0-334.0  [224.17, 224.43, 224.75, 225.25, 229.57]  224.17-229.57  \n",
       "0   382.0-413.0  [265.91, 272.71, 272.93, 273.94, 276.48]  265.91-276.48  \n",
       "0   806.0-817.0  [599.65, 603.74, 604.48, 606.87, 612.88]  599.65-612.88  \n",
       "0   806.0-818.0  [599.67, 604.08, 604.57, 606.86, 613.25]  599.67-613.25  \n",
       "0   806.0-818.0  [599.67, 604.08, 604.57, 606.86, 613.25]  599.67-613.25  \n",
       "0   863.0-886.0  [638.17, 643.96, 646.54, 646.91, 668.87]  638.17-668.87  \n",
       "0   806.0-817.0  [599.57, 603.69, 604.48, 606.85, 612.88]  599.57-612.88  \n",
       "0   351.0-369.0   [264.28, 264.31, 264.82, 267.54, 272.7]   264.28-272.7  \n",
       "0   403.0-435.0    [292.7, 303.9, 304.22, 304.31, 308.96]   292.7-308.96  \n",
       "0   880.0-968.0   [632.76, 639.1, 639.86, 666.64, 686.81]  632.76-686.81  \n",
       "0   604.0-649.0  [445.04, 453.04, 464.57, 466.71, 467.52]  445.04-467.52  \n",
       "0   880.0-954.0  [636.73, 637.26, 642.49, 676.06, 676.63]  636.73-676.63  \n",
       "0   604.0-651.0   [444.05, 453.76, 462.01, 463.62, 467.3]   444.05-467.3  \n",
       "0   392.0-432.0    [283.6, 292.89, 296.46, 300.2, 300.94]   283.6-300.94  \n",
       "0   387.0-423.0  [283.04, 293.27, 295.01, 299.56, 303.83]  283.04-303.83  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_XGBRFR=XGBRFRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "               colsample_bytree=1, gamma=0, gpu_id=-1, importance_type='gain',\n",
    "               interaction_constraints='', max_delta_step=0, max_depth=15,\n",
    "               max_features='auto', min_child_weight=1, min_samples_leaf=3,\n",
    "               min_samples_split=2, missing=np.nan, monotone_constraints='()',\n",
    "               n_estimators=120, n_jobs=0, num_parallel_tree=120,\n",
    "               objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
    "               scale_pos_weight=1, tree_method='exact', validate_parameters=1,\n",
    "               verbosity=None)\n",
    "\n",
    "#Fitting the final model after gridsearch\n",
    "# 25.Randorm Forest Regressor\n",
    "approach='Model Training after Hyperparameter Tuning'\n",
    "model_obj=model_XGBRFR\n",
    "model_name='XGBoost RFRegressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Time-series model on the data taking time as the only feature.This will be a store-level training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets take data only for one store and build a time series model.Lets rendomly select store ID3\n",
    "traindata=traindata_init[(traindata_init.Sales !=0)&(traindata_init.Store==3)][['Date','Sales']]\n",
    "traindata['Date']=pd.to_datetime(traindata['Date'])\n",
    "traindata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "testdata=test_hiddata_init[(test_hiddata_init.Sales !=0)&(test_hiddata_init.Store==3)][['Date','Sales']]\n",
    "testdata['Date']=pd.to_datetime(testdata['Date'])\n",
    "testdata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "## Step 2: Visualize the Data\n",
    "traindata[0:50].plot(x='Date',y='Sales')\n",
    "plt.show()\n",
    "\n",
    "## Step 3: Visualize the Data\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "autocorrelation_plot(traindata[0:50]['Sales'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Test Statistic : -5.686600936105958\n",
      "p-value : 8.251894494716104e-07\n",
      "#Lags Used : 19\n",
      "Number of Observations Used : 732\n",
      "strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Step 4: Testing For Stationarity with Augmented Dickey-Fuller-Test\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "#Hypothesis Testing\n",
    "#Ho: It is non stationary\n",
    "#H1: It is stationary\n",
    "\n",
    "def adfuller_test(sales):\n",
    "    result=adfuller(sales)\n",
    "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "    for value,label in zip(result,labels):\n",
    "        print(label+' : '+str(value) )\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")\n",
    "        \n",
    "adfuller_test(traindata['Sales'])\n",
    "\n",
    "\n",
    "## Step 5:\n",
    "# Find out the value of p, q and d.\n",
    "# p : lag of Auto regressive(AR) model\n",
    "# q: lag of Moving Average(MA) Model\n",
    "# d: differencing\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(traindata['Sales'],lags=50,ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = plot_pacf(traindata['Sales'],lags=50,ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "    From above ACF and PACF plot it is evident that both ACF and PACF are having Geometric Decay.\n",
    "    Therfore we can go for ARIMA model with different combinations of p,d and q values and select the model with minimal AIC,    BIC value. Below combinations of p,d,q were tried and found that (2,0,2) combination produces the least AIC and BIC value.\n",
    "    (2,0,2)  (1,0,1)  (0,0,1)  (0,0,2)   (1,0,2)   (2,0,1)   (1,0,0)  (2,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>ARMA Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Sales</td>      <th>  No. Observations:  </th>    <td>752</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>ARMA(2, 2)</td>    <th>  Log Likelihood     </th> <td>-6757.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>css-mle</td>     <th>  S.D. of innovations</th> <td>1931.697</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 03 Sep 2020</td> <th>  AIC                </th> <td>13526.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>23:49:31</td>     <th>  BIC                </th> <td>13554.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                <td>0</td>        <th>  HQIC               </th> <td>13537.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                       <td> </td>        <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td> 6949.3994</td> <td>   78.577</td> <td>   88.441</td> <td> 0.000</td> <td> 6795.392</td> <td> 7103.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L1.Sales</th> <td>    1.6853</td> <td>    0.021</td> <td>   81.435</td> <td> 0.000</td> <td>    1.645</td> <td>    1.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L2.Sales</th> <td>   -0.9465</td> <td>    0.019</td> <td>  -50.184</td> <td> 0.000</td> <td>   -0.984</td> <td>   -0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L1.Sales</th> <td>   -1.5033</td> <td>    0.039</td> <td>  -38.587</td> <td> 0.000</td> <td>   -1.580</td> <td>   -1.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L2.Sales</th> <td>    0.7945</td> <td>    0.032</td> <td>   24.977</td> <td> 0.000</td> <td>    0.732</td> <td>    0.857</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Roots</caption>\n",
       "<tr>\n",
       "    <td></td>   <th>            Real</th>  <th>         Imaginary</th> <th>         Modulus</th>  <th>        Frequency</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.1</th> <td>           0.8902</td> <td>          -0.5138j</td> <td>           1.0278</td> <td>          -0.0833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.2</th> <td>           0.8902</td> <td>          +0.5138j</td> <td>           1.0278</td> <td>           0.0833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MA.1</th> <td>           0.9460</td> <td>          -0.6030j</td> <td>           1.1219</td> <td>          -0.0903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MA.2</th> <td>           0.9460</td> <td>          +0.6030j</td> <td>           1.1219</td> <td>           0.0903</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              ARMA Model Results                              \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   No. Observations:                  752\n",
       "Model:                     ARMA(2, 2)   Log Likelihood               -6757.351\n",
       "Method:                       css-mle   S.D. of innovations           1931.697\n",
       "Date:                Thu, 03 Sep 2020   AIC                          13526.702\n",
       "Time:                        23:49:31   BIC                          13554.438\n",
       "Sample:                             0   HQIC                         13537.388\n",
       "                                                                              \n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const        6949.3994     78.577     88.441      0.000    6795.392    7103.407\n",
       "ar.L1.Sales     1.6853      0.021     81.435      0.000       1.645       1.726\n",
       "ar.L2.Sales    -0.9465      0.019    -50.184      0.000      -0.984      -0.910\n",
       "ma.L1.Sales    -1.5033      0.039    -38.587      0.000      -1.580      -1.427\n",
       "ma.L2.Sales     0.7945      0.032     24.977      0.000       0.732       0.857\n",
       "                                    Roots                                    \n",
       "=============================================================================\n",
       "                  Real          Imaginary           Modulus         Frequency\n",
       "-----------------------------------------------------------------------------\n",
       "AR.1            0.8902           -0.5138j            1.0278           -0.0833\n",
       "AR.2            0.8902           +0.5138j            1.0278            0.0833\n",
       "MA.1            0.9460           -0.6030j            1.1219           -0.0903\n",
       "MA.2            0.9460           +0.6030j            1.1219            0.0903\n",
       "-----------------------------------------------------------------------------\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6:ARIMA Modeling\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "model=ARIMA(traindata['Sales'],order=(2,0,2))\n",
    "model_fit=model.fit()\n",
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d3b7db5d08>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Step 7: Prediction Train Data\n",
    "traindata['forecast']=model_fit.predict().round()\n",
    "traindata[['Sales','forecast']].plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d3b81d1b48>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Step 7: Prediction Test Data\n",
    "testdata['forecast']=model_fit.predict().round()\n",
    "testdata[['Sales','forecast']].plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score is : 0.23 and Test Score is :-0.23 for store #3\n"
     ]
    }
   ],
   "source": [
    "#Step8: Model Evaluation\n",
    "train_score=round(r2_score(y_true=traindata.Sales, y_pred=traindata.forecast),2)\n",
    "test_score=round(r2_score(y_true=testdata.Sales, y_pred=testdata.forecast),2)\n",
    "print('Train Score is : {} and Test Score is :{} for store #3'.format(train_score,test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 3\n",
    "\n",
    "**Implementing Neural Networks:**\n",
    "\n",
    "1. Train a LSTM on the same set of features and compare the result with traditional time-series model.\n",
    "       \n",
    "2. Comment on the behavior of all the models you have built so far.\n",
    "\n",
    "3. Cluster stores using sales and customer visits as features. Find out how many clusters or groups are possible. Also visualize the results.\n",
    "\n",
    "4. Is it possible to have separate prediction models for each cluster? Compare results with the previous models\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7550 7550 270 270\n"
     ]
    }
   ],
   "source": [
    "#Prepare Data\n",
    "traindata=traindata_init[(traindata_init.Sales !=0)&(traindata_init.Store.isin(storeList))]\n",
    "traindata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "test_hiddata=test_hiddata_init[(test_hiddata_init.Sales !=0)&(test_hiddata_init.Store.isin(storeList))]\n",
    "test_hiddata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "X_train=traindata.drop(columns=['Sales','Date','Store']).values.astype('float32')\n",
    "X_test=test_hiddata.drop(columns=['Sales','Date','Store']).values.astype('float32')\n",
    "#X_train=SC.fit_transform(X_train) # Perform feature scaling on train  data\n",
    "#X_test=SC.fit_transform(X_test) # Perform feature scaling on test data\n",
    "\n",
    "y_train=traindata.Sales.values.astype('float32')\n",
    "y_test=test_hiddata.Sales.values.astype('float32')\n",
    "\n",
    "#print(len(X_train),len(y_train), len(X_test),len(y_test))\n",
    "\n",
    "#The LSTM network expects the input data (X) to be provided with a specific array structure in the form of: \n",
    "#[samples, time steps, features].\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print(len(X_train),len(y_train), len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,LSTM,Flatten,Dropout,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7550 samples, validate on 270 samples\n",
      "7550/7550 [==============================] - 5s 629us/sample - loss: 45223655.3918 - val_loss: 49459395.9704\n",
      "Wall time: 5.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d3cdfa6708>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Initialize Sequential model\n",
    "model_LSTM = Sequential()\n",
    "\n",
    "#Input Layer and Normalize input data\n",
    "model_LSTM.add(LSTM(50,return_sequences=True))\n",
    "model_LSTM.add(BatchNormalization())\n",
    "\n",
    "#First Hidden Layer\n",
    "model_LSTM.add(LSTM(50))\n",
    "model_LSTM.add(BatchNormalization())\n",
    "\n",
    "#Output Layer\n",
    "model_LSTM.add(Dense(1))\n",
    "\n",
    "#Compile the model\n",
    "model_LSTM.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#Train The model\n",
    "model_LSTM.fit(X_train,y_train,          \n",
    "          validation_data=(X_test,y_test),\n",
    "          epochs=1,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train LSTM with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 21s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 413.0]</td>\n",
       "      <td>382.0-413.0</td>\n",
       "      <td>[265.91, 272.71, 272.93, 273.94, 276.48]</td>\n",
       "      <td>265.91-276.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 411.0, 419.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.7, 303.9, 304.22, 304.31, 308.96]</td>\n",
       "      <td>292.7-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 912.0, 932.0, 968.0]</td>\n",
       "      <td>880.0-968.0</td>\n",
       "      <td>[632.76, 639.1, 639.86, 666.64, 686.81]</td>\n",
       "      <td>632.76-686.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 632.0, 649.0]</td>\n",
       "      <td>604.0-649.0</td>\n",
       "      <td>[445.04, 453.04, 464.57, 466.71, 467.52]</td>\n",
       "      <td>445.04-467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 909.0, 935.0, 954.0]</td>\n",
       "      <td>880.0-954.0</td>\n",
       "      <td>[636.73, 637.26, 642.49, 676.06, 676.63]</td>\n",
       "      <td>636.73-676.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 631.0, 651.0]</td>\n",
       "      <td>604.0-651.0</td>\n",
       "      <td>[444.05, 453.76, 462.01, 463.62, 467.3]</td>\n",
       "      <td>444.05-467.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[392.0, 404.0, 406.0, 432.0, 432.0]</td>\n",
       "      <td>392.0-432.0</td>\n",
       "      <td>[283.6, 292.89, 296.46, 300.2, 300.94]</td>\n",
       "      <td>283.6-300.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>XGBoost RFRegressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[387.0, 400.0, 406.0, 420.0, 423.0]</td>\n",
       "      <td>387.0-423.0</td>\n",
       "      <td>[283.04, 293.27, 295.01, 299.56, 303.83]</td>\n",
       "      <td>283.04-303.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.53, 0.64, 0.83, 0.86, 0.87]</td>\n",
       "      <td>0.53-0.87</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[888.0, 895.0, 968.0, 1440.0, 1649.0]</td>\n",
       "      <td>888.0-1649.0</td>\n",
       "      <td>[675.77, 678.72, 681.47, 1289.21, 1333.7]</td>\n",
       "      <td>675.77001953125-1333.699951171875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0                                               LSTM   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Random Forest Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                        XGBoost RFRegressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                                       LSTM  [0.53, 0.64, 0.83, 0.86, 0.87]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                   RMSE  \\\n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00    [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01    [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01    [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00    [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01    [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00    [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00    [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00    [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00    [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00    [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01    [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00    [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01    [382.0, 387.0, 390.0, 396.0, 413.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.85-0.87             0.01    [863.0, 877.0, 878.0, 879.0, 886.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.98-0.98             0.00    [351.0, 356.0, 361.0, 365.0, 369.0]   \n",
       "0          0.97-0.97             0.00    [403.0, 411.0, 419.0, 431.0, 435.0]   \n",
       "0          0.84-0.86             0.01    [880.0, 885.0, 912.0, 932.0, 968.0]   \n",
       "0          0.93-0.94             0.00    [604.0, 611.0, 625.0, 632.0, 649.0]   \n",
       "0          0.84-0.86             0.01    [880.0, 885.0, 909.0, 935.0, 954.0]   \n",
       "0          0.93-0.94             0.00    [604.0, 611.0, 625.0, 631.0, 651.0]   \n",
       "0          0.97-0.97             0.00    [392.0, 404.0, 406.0, 432.0, 432.0]   \n",
       "0          0.97-0.97             0.00    [387.0, 400.0, 406.0, 420.0, 423.0]   \n",
       "0          0.53-0.87             0.15  [888.0, 895.0, 968.0, 1440.0, 1649.0]   \n",
       "\n",
       "  Range of RMSE                                        MAE  \\\n",
       "0   747.0-761.0   [539.01, 544.88, 548.35, 548.62, 554.01]   \n",
       "0   243.0-264.0   [189.32, 191.26, 195.81, 199.95, 204.91]   \n",
       "0   420.0-598.0      [304.21, 326.6, 333.4, 333.8, 340.42]   \n",
       "0   450.0-587.0    [348.45, 360.18, 373.76, 402.8, 404.99]   \n",
       "0   389.0-461.0    [288.51, 303.81, 304.2, 305.83, 345.36]   \n",
       "0   425.0-511.0   [322.94, 332.13, 334.76, 347.04, 353.21]   \n",
       "0   308.0-343.0    [228.1, 238.39, 251.72, 253.29, 265.95]   \n",
       "0   661.0-725.0    [479.93, 502.99, 507.38, 510.57, 515.9]   \n",
       "0   411.0-493.0   [313.53, 319.11, 344.25, 361.63, 363.62]   \n",
       "0   348.0-387.0   [248.59, 249.59, 261.29, 261.74, 261.85]   \n",
       "0   326.0-348.0   [253.24, 253.97, 254.97, 257.17, 261.38]   \n",
       "0   747.0-761.0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   747.0-761.0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   823.0-831.0   [584.13, 588.87, 593.47, 595.88, 603.25]   \n",
       "0   747.0-761.0   [539.01, 544.88, 548.35, 548.61, 554.01]   \n",
       "0   327.0-334.0   [224.17, 224.43, 224.75, 225.25, 229.57]   \n",
       "0   382.0-413.0   [265.91, 272.71, 272.93, 273.94, 276.48]   \n",
       "0   806.0-817.0   [599.65, 603.74, 604.48, 606.87, 612.88]   \n",
       "0   806.0-818.0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   806.0-818.0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   863.0-886.0   [638.17, 643.96, 646.54, 646.91, 668.87]   \n",
       "0   806.0-817.0   [599.57, 603.69, 604.48, 606.85, 612.88]   \n",
       "0   351.0-369.0    [264.28, 264.31, 264.82, 267.54, 272.7]   \n",
       "0   403.0-435.0     [292.7, 303.9, 304.22, 304.31, 308.96]   \n",
       "0   880.0-968.0    [632.76, 639.1, 639.86, 666.64, 686.81]   \n",
       "0   604.0-649.0   [445.04, 453.04, 464.57, 466.71, 467.52]   \n",
       "0   880.0-954.0   [636.73, 637.26, 642.49, 676.06, 676.63]   \n",
       "0   604.0-651.0    [444.05, 453.76, 462.01, 463.62, 467.3]   \n",
       "0   392.0-432.0     [283.6, 292.89, 296.46, 300.2, 300.94]   \n",
       "0   387.0-423.0   [283.04, 293.27, 295.01, 299.56, 303.83]   \n",
       "0  888.0-1649.0  [675.77, 678.72, 681.47, 1289.21, 1333.7]   \n",
       "\n",
       "                        Range of MAE  \n",
       "0                      539.01-554.01  \n",
       "0                      189.32-204.91  \n",
       "0                      304.21-340.42  \n",
       "0                      348.45-404.99  \n",
       "0                      288.51-345.36  \n",
       "0                      322.94-353.21  \n",
       "0                       228.1-265.95  \n",
       "0                       479.93-515.9  \n",
       "0                      313.53-363.62  \n",
       "0                      248.59-261.85  \n",
       "0                      253.24-261.38  \n",
       "0                      538.52-553.62  \n",
       "0                      538.52-553.62  \n",
       "0                      584.13-603.25  \n",
       "0                      539.01-554.01  \n",
       "0                      224.17-229.57  \n",
       "0                      265.91-276.48  \n",
       "0                      599.65-612.88  \n",
       "0                      599.67-613.25  \n",
       "0                      599.67-613.25  \n",
       "0                      638.17-668.87  \n",
       "0                      599.57-612.88  \n",
       "0                       264.28-272.7  \n",
       "0                       292.7-308.96  \n",
       "0                      632.76-686.81  \n",
       "0                      445.04-467.52  \n",
       "0                      636.73-676.63  \n",
       "0                       444.05-467.3  \n",
       "0                       283.6-300.94  \n",
       "0                      283.04-303.83  \n",
       "0  675.77001953125-1333.699951171875  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 27.LSTM\n",
    "global df_model_selection\n",
    "\n",
    "#Initialize Sequential model\n",
    "model_LSTM = Sequential()\n",
    "\n",
    "#Input Layer and Normalize input data\n",
    "#model_LSTM.add(LSTM(50,return_sequences=True))\n",
    "#model_LSTM.add(BatchNormalization())\n",
    "\n",
    "#First Hidden Layer\n",
    "model_LSTM.add(LSTM(50))\n",
    "model_LSTM.add(BatchNormalization())\n",
    "\n",
    "#Output Layer\n",
    "model_LSTM.add(Dense(1))\n",
    "\n",
    "#Compile the model\n",
    "model_LSTM.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#Train The model with Cross Validation\n",
    "approach='LSTM'\n",
    "model_obj=model_LSTM\n",
    "model_name='LSTM'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "#Exporting the results to csv\n",
    "#df_model_selection.to_csv(\"Model_statistics-Until_LSTM\",index = False)\n",
    "\n",
    "df_model_selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "    1. So far we have performed different approaches of model training and testing including Linear model, Boosting Model,   Ensemble model, PCA, Kernel PCA, Time Series and LSTM model. \n",
    "    2. We have also built and tested the models with single store as well as Combination of stores(10 Stores)\n",
    "    3. We have also built and tested model after removing the data where sales = 0.\n",
    "    4. Above test results shows that, \n",
    "           a)LSTM performance is better than traditional Time series model.\n",
    "           b)Ensemble techniqe is performing well but not much of difference as compared to individual model.\n",
    "           c) Removing sales=0 data did not improve the peformance rather it had a negative impact on overall performance\n",
    "           d)Among all the approaches, there are two approaches that stands out  until now and those are \n",
    "             Gradient Boosting and XGBoost Regressor with all features taken into account\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Tasks: Week 3\n",
    "    Cluster stores using sales and customer visits as features. Find out how many clusters or groups are possible. \n",
    "    Also visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7550, 2) (270, 2)\n"
     ]
    }
   ],
   "source": [
    "#Prepare Data\n",
    "\n",
    "traindata=traindata_init[(traindata_init.Sales !=0)&(traindata_init.Store.isin(storeList))]\n",
    "traindata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "test_hiddata=test_hiddata_init[(test_hiddata_init.Sales !=0)&(test_hiddata_init.Store.isin(storeList))]\n",
    "test_hiddata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "X_train=traindata[['Customers','Sales']]\n",
    "X_test=test_hiddata[['Customers','Sales']]\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x20028fa90c8>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the possible clusters\n",
    "sns.pairplot(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5, random_state=10)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model_KMeans = KMeans(n_clusters=5,random_state=10)\n",
    "model_KMeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterTrain=model_KMeans.predict(X_train)\n",
    "ClusterTest=model_KMeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata['Cluster']=ClusterTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayofYear</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106</td>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7545</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>6089</td>\n",
       "      <td>781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7546</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>8244</td>\n",
       "      <td>955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7547</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>5419</td>\n",
       "      <td>698</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7548</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4903</td>\n",
       "      <td>481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4812</td>\n",
       "      <td>521</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7550 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store  Week  Day  DayofYear  DayOfWeek       Date  Sales  Customers  \\\n",
       "0         1    27   30        181          2 2015-06-30   5735        568   \n",
       "1         2    27   30        181          2 2015-06-30   9863        877   \n",
       "2         3    27   30        181          2 2015-06-30  13261       1072   \n",
       "3         4    27   30        181          2 2015-06-30  13106       1488   \n",
       "4         5    27   30        181          2 2015-06-30   6635        645   \n",
       "...     ...   ...  ...        ...        ...        ...    ...        ...   \n",
       "7545      6     1    2          2          3 2013-01-02   6089        781   \n",
       "7546      7     1    2          2          3 2013-01-02   8244        955   \n",
       "7547      8     1    2          2          3 2013-01-02   5419        698   \n",
       "7548      9     1    2          2          3 2013-01-02   4903        481   \n",
       "7549     10     1    2          2          3 2013-01-02   4812        521   \n",
       "\n",
       "      Open  Promo  StateHoliday  SchoolHoliday  Cluster  \n",
       "0        1      1             0              0        0  \n",
       "1        1      1             0              0        1  \n",
       "2        1      1             0              1        4  \n",
       "3        1      1             0              0        4  \n",
       "4        1      1             0              0        2  \n",
       "...    ...    ...           ...            ...      ...  \n",
       "7545     1      0             0              1        0  \n",
       "7546     1      0             0              1        2  \n",
       "7547     1      0             0              1        0  \n",
       "7548     1      0             0              1        0  \n",
       "7549     1      0             0              1        0  \n",
       "\n",
       "[7550 rows x 13 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20029686548>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To verify the number of clusters we can use Elbow method using Kmeans++\n",
    "# In kmeans, the metric that we use to check the quality of cluster group creation is \n",
    "# WCSS(Within Cluster Sum of Squares)\n",
    "\n",
    "wcss=[]\n",
    "for i in range(1,10):\n",
    "    model_KMeans = KMeans(n_clusters=i)\n",
    "    model_KMeans.fit(X_train)\n",
    "    wcss.append(model_KMeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,10),wcss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above plot we can considere the number of cluster to be either 2 or 3.\n",
    "model_KMeans = KMeans(n_clusters=2,random_state=10)\n",
    "model_KMeans.fit(X_train)\n",
    "ClusterTrain=model_KMeans.predict(X_train)\n",
    "ClusterTest=model_KMeans.predict(X_test)\n",
    "\n",
    "traindata['Cluster']=ClusterTrain\n",
    "test_hiddata['Cluster']=ClusterTest\n",
    "traindata.Cluster.replace([0,1],['Cluster1','Cluster2'],inplace=True)\n",
    "test_hiddata.Cluster.replace([0,1],['Cluster1','Cluster2'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>DayofYear</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>5735</td>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>9863</td>\n",
       "      <td>877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cluster2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13261</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cluster2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>13106</td>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cluster2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>6635</td>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7545</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>6089</td>\n",
       "      <td>781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7546</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>8244</td>\n",
       "      <td>955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cluster2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7547</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>5419</td>\n",
       "      <td>698</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7548</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4903</td>\n",
       "      <td>481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4812</td>\n",
       "      <td>521</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cluster1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7550 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store  Week  Day  DayofYear  DayOfWeek       Date  Sales  Customers  \\\n",
       "0         1    27   30        181          2 2015-06-30   5735        568   \n",
       "1         2    27   30        181          2 2015-06-30   9863        877   \n",
       "2         3    27   30        181          2 2015-06-30  13261       1072   \n",
       "3         4    27   30        181          2 2015-06-30  13106       1488   \n",
       "4         5    27   30        181          2 2015-06-30   6635        645   \n",
       "...     ...   ...  ...        ...        ...        ...    ...        ...   \n",
       "7545      6     1    2          2          3 2013-01-02   6089        781   \n",
       "7546      7     1    2          2          3 2013-01-02   8244        955   \n",
       "7547      8     1    2          2          3 2013-01-02   5419        698   \n",
       "7548      9     1    2          2          3 2013-01-02   4903        481   \n",
       "7549     10     1    2          2          3 2013-01-02   4812        521   \n",
       "\n",
       "      Open  Promo  StateHoliday  SchoolHoliday   Cluster  \n",
       "0        1      1             0              0  Cluster1  \n",
       "1        1      1             0              0  Cluster2  \n",
       "2        1      1             0              1  Cluster2  \n",
       "3        1      1             0              0  Cluster2  \n",
       "4        1      1             0              0  Cluster1  \n",
       "...    ...    ...           ...            ...       ...  \n",
       "7545     1      0             0              1  Cluster1  \n",
       "7546     1      0             0              1  Cluster2  \n",
       "7547     1      0             0              1  Cluster1  \n",
       "7548     1      0             0              1  Cluster1  \n",
       "7549     1      0             0              1  Cluster1  \n",
       "\n",
       "[7550 rows x 13 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster1    5131\n",
       "Cluster2    2419\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.Cluster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build separate prediction models for each cluster and Compare results with the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5131 5131 180 180\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 413.0]</td>\n",
       "      <td>382.0-413.0</td>\n",
       "      <td>[265.91, 272.71, 272.93, 273.94, 276.48]</td>\n",
       "      <td>265.91-276.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 411.0, 419.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.7, 303.9, 304.22, 304.31, 308.96]</td>\n",
       "      <td>292.7-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 912.0, 932.0, 968.0]</td>\n",
       "      <td>880.0-968.0</td>\n",
       "      <td>[632.76, 639.1, 639.86, 666.64, 686.81]</td>\n",
       "      <td>632.76-686.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 632.0, 649.0]</td>\n",
       "      <td>604.0-649.0</td>\n",
       "      <td>[445.04, 453.04, 464.57, 466.71, 467.52]</td>\n",
       "      <td>445.04-467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 909.0, 935.0, 954.0]</td>\n",
       "      <td>880.0-954.0</td>\n",
       "      <td>[636.73, 637.26, 642.49, 676.06, 676.63]</td>\n",
       "      <td>636.73-676.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 631.0, 651.0]</td>\n",
       "      <td>604.0-651.0</td>\n",
       "      <td>[444.05, 453.76, 462.01, 463.62, 467.3]</td>\n",
       "      <td>444.05-467.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[392.0, 404.0, 406.0, 432.0, 432.0]</td>\n",
       "      <td>392.0-432.0</td>\n",
       "      <td>[283.6, 292.89, 296.46, 300.2, 300.94]</td>\n",
       "      <td>283.6-300.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>XGBoost RFRegressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[387.0, 400.0, 406.0, 420.0, 423.0]</td>\n",
       "      <td>387.0-423.0</td>\n",
       "      <td>[283.04, 293.27, 295.01, 299.56, 303.83]</td>\n",
       "      <td>283.04-303.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.53, 0.64, 0.83, 0.86, 0.87]</td>\n",
       "      <td>0.53-0.87</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[888.0, 895.0, 968.0, 1440.0, 1649.0]</td>\n",
       "      <td>888.0-1649.0</td>\n",
       "      <td>[675.77, 678.72, 681.47, 1289.21, 1333.7]</td>\n",
       "      <td>675.77001953125-1333.699951171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster1 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.94, 0.94, 0.95, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[271.0, 274.0, 276.0, 282.0, 282.0]</td>\n",
       "      <td>271.0-282.0</td>\n",
       "      <td>[211.21, 215.0, 217.17, 217.75, 218.49]</td>\n",
       "      <td>211.21-218.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0                                               LSTM   \n",
       "0                 Model Training with  Cluster1 Data   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Random Forest Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                        XGBoost RFRegressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                                       LSTM  [0.53, 0.64, 0.83, 0.86, 0.87]   \n",
       "0                          XGBoost Regressor  [0.94, 0.94, 0.95, 0.95, 0.95]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                   RMSE  \\\n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00    [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01    [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01    [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00    [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01    [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00    [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00    [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00    [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00    [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00    [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01    [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00    [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01    [382.0, 387.0, 390.0, 396.0, 413.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.85-0.87             0.01    [863.0, 877.0, 878.0, 879.0, 886.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.98-0.98             0.00    [351.0, 356.0, 361.0, 365.0, 369.0]   \n",
       "0          0.97-0.97             0.00    [403.0, 411.0, 419.0, 431.0, 435.0]   \n",
       "0          0.84-0.86             0.01    [880.0, 885.0, 912.0, 932.0, 968.0]   \n",
       "0          0.93-0.94             0.00    [604.0, 611.0, 625.0, 632.0, 649.0]   \n",
       "0          0.84-0.86             0.01    [880.0, 885.0, 909.0, 935.0, 954.0]   \n",
       "0          0.93-0.94             0.00    [604.0, 611.0, 625.0, 631.0, 651.0]   \n",
       "0          0.97-0.97             0.00    [392.0, 404.0, 406.0, 432.0, 432.0]   \n",
       "0          0.97-0.97             0.00    [387.0, 400.0, 406.0, 420.0, 423.0]   \n",
       "0          0.53-0.87             0.15  [888.0, 895.0, 968.0, 1440.0, 1649.0]   \n",
       "0          0.94-0.95             0.01    [271.0, 274.0, 276.0, 282.0, 282.0]   \n",
       "\n",
       "  Range of RMSE                                        MAE  \\\n",
       "0   747.0-761.0   [539.01, 544.88, 548.35, 548.62, 554.01]   \n",
       "0   243.0-264.0   [189.32, 191.26, 195.81, 199.95, 204.91]   \n",
       "0   420.0-598.0      [304.21, 326.6, 333.4, 333.8, 340.42]   \n",
       "0   450.0-587.0    [348.45, 360.18, 373.76, 402.8, 404.99]   \n",
       "0   389.0-461.0    [288.51, 303.81, 304.2, 305.83, 345.36]   \n",
       "0   425.0-511.0   [322.94, 332.13, 334.76, 347.04, 353.21]   \n",
       "0   308.0-343.0    [228.1, 238.39, 251.72, 253.29, 265.95]   \n",
       "0   661.0-725.0    [479.93, 502.99, 507.38, 510.57, 515.9]   \n",
       "0   411.0-493.0   [313.53, 319.11, 344.25, 361.63, 363.62]   \n",
       "0   348.0-387.0   [248.59, 249.59, 261.29, 261.74, 261.85]   \n",
       "0   326.0-348.0   [253.24, 253.97, 254.97, 257.17, 261.38]   \n",
       "0   747.0-761.0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   747.0-761.0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   823.0-831.0   [584.13, 588.87, 593.47, 595.88, 603.25]   \n",
       "0   747.0-761.0   [539.01, 544.88, 548.35, 548.61, 554.01]   \n",
       "0   327.0-334.0   [224.17, 224.43, 224.75, 225.25, 229.57]   \n",
       "0   382.0-413.0   [265.91, 272.71, 272.93, 273.94, 276.48]   \n",
       "0   806.0-817.0   [599.65, 603.74, 604.48, 606.87, 612.88]   \n",
       "0   806.0-818.0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   806.0-818.0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   863.0-886.0   [638.17, 643.96, 646.54, 646.91, 668.87]   \n",
       "0   806.0-817.0   [599.57, 603.69, 604.48, 606.85, 612.88]   \n",
       "0   351.0-369.0    [264.28, 264.31, 264.82, 267.54, 272.7]   \n",
       "0   403.0-435.0     [292.7, 303.9, 304.22, 304.31, 308.96]   \n",
       "0   880.0-968.0    [632.76, 639.1, 639.86, 666.64, 686.81]   \n",
       "0   604.0-649.0   [445.04, 453.04, 464.57, 466.71, 467.52]   \n",
       "0   880.0-954.0   [636.73, 637.26, 642.49, 676.06, 676.63]   \n",
       "0   604.0-651.0    [444.05, 453.76, 462.01, 463.62, 467.3]   \n",
       "0   392.0-432.0     [283.6, 292.89, 296.46, 300.2, 300.94]   \n",
       "0   387.0-423.0   [283.04, 293.27, 295.01, 299.56, 303.83]   \n",
       "0  888.0-1649.0  [675.77, 678.72, 681.47, 1289.21, 1333.7]   \n",
       "0   271.0-282.0    [211.21, 215.0, 217.17, 217.75, 218.49]   \n",
       "\n",
       "                        Range of MAE  \n",
       "0                      539.01-554.01  \n",
       "0                      189.32-204.91  \n",
       "0                      304.21-340.42  \n",
       "0                      348.45-404.99  \n",
       "0                      288.51-345.36  \n",
       "0                      322.94-353.21  \n",
       "0                       228.1-265.95  \n",
       "0                       479.93-515.9  \n",
       "0                      313.53-363.62  \n",
       "0                      248.59-261.85  \n",
       "0                      253.24-261.38  \n",
       "0                      538.52-553.62  \n",
       "0                      538.52-553.62  \n",
       "0                      584.13-603.25  \n",
       "0                      539.01-554.01  \n",
       "0                      224.17-229.57  \n",
       "0                      265.91-276.48  \n",
       "0                      599.65-612.88  \n",
       "0                      599.67-613.25  \n",
       "0                      599.67-613.25  \n",
       "0                      638.17-668.87  \n",
       "0                      599.57-612.88  \n",
       "0                       264.28-272.7  \n",
       "0                       292.7-308.96  \n",
       "0                      632.76-686.81  \n",
       "0                      445.04-467.52  \n",
       "0                      636.73-676.63  \n",
       "0                       444.05-467.3  \n",
       "0                       283.6-300.94  \n",
       "0                      283.04-303.83  \n",
       "0  675.77001953125-1333.699951171875  \n",
       "0                      211.21-218.49  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare Data for Cluster1\n",
    "\n",
    "train_cluster1=traindata[traindata.Cluster=='Cluster1']\n",
    "test_cluster1=test_hiddata[test_hiddata.Cluster=='Cluster1']\n",
    "\n",
    "X_train=train_cluster1.drop(columns=['Sales','Date','Cluster']).values\n",
    "X_test=test_cluster1.drop(columns=['Sales','Date','Cluster']).values\n",
    "\n",
    "y_train=train_cluster1['Sales'].values\n",
    "y_test=test_cluster1['Sales'].values\n",
    "print(len(X_train),len(y_train), len(X_test),len(y_test))\n",
    "\n",
    "\n",
    "#Lets train and evaluate the best Model(XGBoost Regressor) with Cluster 1 Data\n",
    "approach='Model Training with  Cluster1 Data'\n",
    "model_XGBR=XGBRegressor()\n",
    "model_obj=model_XGBR\n",
    "model_name='XGBoost Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2419 2419 90 90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 413.0]</td>\n",
       "      <td>382.0-413.0</td>\n",
       "      <td>[265.91, 272.71, 272.93, 273.94, 276.48]</td>\n",
       "      <td>265.91-276.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 411.0, 419.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.7, 303.9, 304.22, 304.31, 308.96]</td>\n",
       "      <td>292.7-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 912.0, 932.0, 968.0]</td>\n",
       "      <td>880.0-968.0</td>\n",
       "      <td>[632.76, 639.1, 639.86, 666.64, 686.81]</td>\n",
       "      <td>632.76-686.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 632.0, 649.0]</td>\n",
       "      <td>604.0-649.0</td>\n",
       "      <td>[445.04, 453.04, 464.57, 466.71, 467.52]</td>\n",
       "      <td>445.04-467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 909.0, 935.0, 954.0]</td>\n",
       "      <td>880.0-954.0</td>\n",
       "      <td>[636.73, 637.26, 642.49, 676.06, 676.63]</td>\n",
       "      <td>636.73-676.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 631.0, 651.0]</td>\n",
       "      <td>604.0-651.0</td>\n",
       "      <td>[444.05, 453.76, 462.01, 463.62, 467.3]</td>\n",
       "      <td>444.05-467.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[392.0, 404.0, 406.0, 432.0, 432.0]</td>\n",
       "      <td>392.0-432.0</td>\n",
       "      <td>[283.6, 292.89, 296.46, 300.2, 300.94]</td>\n",
       "      <td>283.6-300.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>XGBoost RFRegressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[387.0, 400.0, 406.0, 420.0, 423.0]</td>\n",
       "      <td>387.0-423.0</td>\n",
       "      <td>[283.04, 293.27, 295.01, 299.56, 303.83]</td>\n",
       "      <td>283.04-303.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.53, 0.64, 0.83, 0.86, 0.87]</td>\n",
       "      <td>0.53-0.87</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[888.0, 895.0, 968.0, 1440.0, 1649.0]</td>\n",
       "      <td>888.0-1649.0</td>\n",
       "      <td>[675.77, 678.72, 681.47, 1289.21, 1333.7]</td>\n",
       "      <td>675.77001953125-1333.699951171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster1 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.94, 0.94, 0.95, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[271.0, 274.0, 276.0, 282.0, 282.0]</td>\n",
       "      <td>271.0-282.0</td>\n",
       "      <td>[211.21, 215.0, 217.17, 217.75, 218.49]</td>\n",
       "      <td>211.21-218.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster2 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.91, 0.92, 0.92, 0.94, 0.94]</td>\n",
       "      <td>0.91-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[449.0, 458.0, 477.0, 510.0, 538.0]</td>\n",
       "      <td>449.0-538.0</td>\n",
       "      <td>[347.72, 348.02, 352.54, 369.51, 393.18]</td>\n",
       "      <td>347.72-393.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0                                               LSTM   \n",
       "0                 Model Training with  Cluster1 Data   \n",
       "0                 Model Training with  Cluster2 Data   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Random Forest Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                        XGBoost RFRegressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                                       LSTM  [0.53, 0.64, 0.83, 0.86, 0.87]   \n",
       "0                          XGBoost Regressor  [0.94, 0.94, 0.95, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.91, 0.92, 0.92, 0.94, 0.94]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                   RMSE  \\\n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00    [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01    [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01    [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00    [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01    [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00    [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00    [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00    [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00    [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00    [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01    [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00    [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01    [382.0, 387.0, 390.0, 396.0, 413.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.85-0.87             0.01    [863.0, 877.0, 878.0, 879.0, 886.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.98-0.98             0.00    [351.0, 356.0, 361.0, 365.0, 369.0]   \n",
       "0          0.97-0.97             0.00    [403.0, 411.0, 419.0, 431.0, 435.0]   \n",
       "0          0.84-0.86             0.01    [880.0, 885.0, 912.0, 932.0, 968.0]   \n",
       "0          0.93-0.94             0.00    [604.0, 611.0, 625.0, 632.0, 649.0]   \n",
       "0          0.84-0.86             0.01    [880.0, 885.0, 909.0, 935.0, 954.0]   \n",
       "0          0.93-0.94             0.00    [604.0, 611.0, 625.0, 631.0, 651.0]   \n",
       "0          0.97-0.97             0.00    [392.0, 404.0, 406.0, 432.0, 432.0]   \n",
       "0          0.97-0.97             0.00    [387.0, 400.0, 406.0, 420.0, 423.0]   \n",
       "0          0.53-0.87             0.15  [888.0, 895.0, 968.0, 1440.0, 1649.0]   \n",
       "0          0.94-0.95             0.01    [271.0, 274.0, 276.0, 282.0, 282.0]   \n",
       "0          0.91-0.94             0.01    [449.0, 458.0, 477.0, 510.0, 538.0]   \n",
       "\n",
       "  Range of RMSE                                        MAE  \\\n",
       "0   747.0-761.0   [539.01, 544.88, 548.35, 548.62, 554.01]   \n",
       "0   243.0-264.0   [189.32, 191.26, 195.81, 199.95, 204.91]   \n",
       "0   420.0-598.0      [304.21, 326.6, 333.4, 333.8, 340.42]   \n",
       "0   450.0-587.0    [348.45, 360.18, 373.76, 402.8, 404.99]   \n",
       "0   389.0-461.0    [288.51, 303.81, 304.2, 305.83, 345.36]   \n",
       "0   425.0-511.0   [322.94, 332.13, 334.76, 347.04, 353.21]   \n",
       "0   308.0-343.0    [228.1, 238.39, 251.72, 253.29, 265.95]   \n",
       "0   661.0-725.0    [479.93, 502.99, 507.38, 510.57, 515.9]   \n",
       "0   411.0-493.0   [313.53, 319.11, 344.25, 361.63, 363.62]   \n",
       "0   348.0-387.0   [248.59, 249.59, 261.29, 261.74, 261.85]   \n",
       "0   326.0-348.0   [253.24, 253.97, 254.97, 257.17, 261.38]   \n",
       "0   747.0-761.0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   747.0-761.0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   823.0-831.0   [584.13, 588.87, 593.47, 595.88, 603.25]   \n",
       "0   747.0-761.0   [539.01, 544.88, 548.35, 548.61, 554.01]   \n",
       "0   327.0-334.0   [224.17, 224.43, 224.75, 225.25, 229.57]   \n",
       "0   382.0-413.0   [265.91, 272.71, 272.93, 273.94, 276.48]   \n",
       "0   806.0-817.0   [599.65, 603.74, 604.48, 606.87, 612.88]   \n",
       "0   806.0-818.0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   806.0-818.0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   863.0-886.0   [638.17, 643.96, 646.54, 646.91, 668.87]   \n",
       "0   806.0-817.0   [599.57, 603.69, 604.48, 606.85, 612.88]   \n",
       "0   351.0-369.0    [264.28, 264.31, 264.82, 267.54, 272.7]   \n",
       "0   403.0-435.0     [292.7, 303.9, 304.22, 304.31, 308.96]   \n",
       "0   880.0-968.0    [632.76, 639.1, 639.86, 666.64, 686.81]   \n",
       "0   604.0-649.0   [445.04, 453.04, 464.57, 466.71, 467.52]   \n",
       "0   880.0-954.0   [636.73, 637.26, 642.49, 676.06, 676.63]   \n",
       "0   604.0-651.0    [444.05, 453.76, 462.01, 463.62, 467.3]   \n",
       "0   392.0-432.0     [283.6, 292.89, 296.46, 300.2, 300.94]   \n",
       "0   387.0-423.0   [283.04, 293.27, 295.01, 299.56, 303.83]   \n",
       "0  888.0-1649.0  [675.77, 678.72, 681.47, 1289.21, 1333.7]   \n",
       "0   271.0-282.0    [211.21, 215.0, 217.17, 217.75, 218.49]   \n",
       "0   449.0-538.0   [347.72, 348.02, 352.54, 369.51, 393.18]   \n",
       "\n",
       "                        Range of MAE  \n",
       "0                      539.01-554.01  \n",
       "0                      189.32-204.91  \n",
       "0                      304.21-340.42  \n",
       "0                      348.45-404.99  \n",
       "0                      288.51-345.36  \n",
       "0                      322.94-353.21  \n",
       "0                       228.1-265.95  \n",
       "0                       479.93-515.9  \n",
       "0                      313.53-363.62  \n",
       "0                      248.59-261.85  \n",
       "0                      253.24-261.38  \n",
       "0                      538.52-553.62  \n",
       "0                      538.52-553.62  \n",
       "0                      584.13-603.25  \n",
       "0                      539.01-554.01  \n",
       "0                      224.17-229.57  \n",
       "0                      265.91-276.48  \n",
       "0                      599.65-612.88  \n",
       "0                      599.67-613.25  \n",
       "0                      599.67-613.25  \n",
       "0                      638.17-668.87  \n",
       "0                      599.57-612.88  \n",
       "0                       264.28-272.7  \n",
       "0                       292.7-308.96  \n",
       "0                      632.76-686.81  \n",
       "0                      445.04-467.52  \n",
       "0                      636.73-676.63  \n",
       "0                       444.05-467.3  \n",
       "0                       283.6-300.94  \n",
       "0                      283.04-303.83  \n",
       "0  675.77001953125-1333.699951171875  \n",
       "0                      211.21-218.49  \n",
       "0                      347.72-393.18  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare Data for Cluster2\n",
    "\n",
    "train_cluster2=traindata[traindata.Cluster=='Cluster2']\n",
    "test_cluster2=test_hiddata[test_hiddata.Cluster=='Cluster2']\n",
    "\n",
    "X_train=train_cluster2.drop(columns=['Sales','Date','Cluster']).values\n",
    "X_test=test_cluster2.drop(columns=['Sales','Date','Cluster']).values\n",
    "\n",
    "y_train=train_cluster2['Sales'].values\n",
    "y_test=test_cluster2['Sales'].values\n",
    "print(len(X_train),len(y_train), len(X_test),len(y_test))\n",
    "\n",
    "\n",
    "#Lets train and evaluate the best Model(XGBoost Regressor) with Cluster 2 Data\n",
    "approach='Model Training with  Cluster2 Data'\n",
    "model_XGBR=XGBRegressor()\n",
    "model_obj=model_XGBR\n",
    "model_name='XGBoost Regressor'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 43s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 413.0]</td>\n",
       "      <td>382.0-413.0</td>\n",
       "      <td>[265.91, 272.71, 272.93, 273.94, 276.48]</td>\n",
       "      <td>265.91-276.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 411.0, 419.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.7, 303.9, 304.22, 304.31, 308.96]</td>\n",
       "      <td>292.7-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 912.0, 932.0, 968.0]</td>\n",
       "      <td>880.0-968.0</td>\n",
       "      <td>[632.76, 639.1, 639.86, 666.64, 686.81]</td>\n",
       "      <td>632.76-686.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 632.0, 649.0]</td>\n",
       "      <td>604.0-649.0</td>\n",
       "      <td>[445.04, 453.04, 464.57, 466.71, 467.52]</td>\n",
       "      <td>445.04-467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 909.0, 935.0, 954.0]</td>\n",
       "      <td>880.0-954.0</td>\n",
       "      <td>[636.73, 637.26, 642.49, 676.06, 676.63]</td>\n",
       "      <td>636.73-676.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 631.0, 651.0]</td>\n",
       "      <td>604.0-651.0</td>\n",
       "      <td>[444.05, 453.76, 462.01, 463.62, 467.3]</td>\n",
       "      <td>444.05-467.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[392.0, 404.0, 406.0, 432.0, 432.0]</td>\n",
       "      <td>392.0-432.0</td>\n",
       "      <td>[283.6, 292.89, 296.46, 300.2, 300.94]</td>\n",
       "      <td>283.6-300.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>XGBoost RFRegressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[387.0, 400.0, 406.0, 420.0, 423.0]</td>\n",
       "      <td>387.0-423.0</td>\n",
       "      <td>[283.04, 293.27, 295.01, 299.56, 303.83]</td>\n",
       "      <td>283.04-303.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.53, 0.64, 0.83, 0.86, 0.87]</td>\n",
       "      <td>0.53-0.87</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[888.0, 895.0, 968.0, 1440.0, 1649.0]</td>\n",
       "      <td>888.0-1649.0</td>\n",
       "      <td>[675.77, 678.72, 681.47, 1289.21, 1333.7]</td>\n",
       "      <td>675.77001953125-1333.699951171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster1 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.94, 0.94, 0.95, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[271.0, 274.0, 276.0, 282.0, 282.0]</td>\n",
       "      <td>271.0-282.0</td>\n",
       "      <td>[211.21, 215.0, 217.17, 217.75, 218.49]</td>\n",
       "      <td>211.21-218.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster2 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.91, 0.92, 0.92, 0.94, 0.94]</td>\n",
       "      <td>0.91-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[449.0, 458.0, 477.0, 510.0, 538.0]</td>\n",
       "      <td>449.0-538.0</td>\n",
       "      <td>[347.72, 348.02, 352.54, 369.51, 393.18]</td>\n",
       "      <td>347.72-393.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM with Cluster1 Data</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.47, 0.62, 0.76, 0.8, 0.8]</td>\n",
       "      <td>0.47-0.8</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[521.0, 533.0, 575.0, 729.0, 887.0]</td>\n",
       "      <td>521.0-887.0</td>\n",
       "      <td>[383.34, 390.09, 415.22, 547.52, 703.45]</td>\n",
       "      <td>383.3399963378906-703.4500122070312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0                                               LSTM   \n",
       "0                 Model Training with  Cluster1 Data   \n",
       "0                 Model Training with  Cluster2 Data   \n",
       "0                            LSTM with Cluster1 Data   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Random Forest Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                        XGBoost RFRegressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                                       LSTM  [0.53, 0.64, 0.83, 0.86, 0.87]   \n",
       "0                          XGBoost Regressor  [0.94, 0.94, 0.95, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.91, 0.92, 0.92, 0.94, 0.94]   \n",
       "0                                       LSTM    [0.47, 0.62, 0.76, 0.8, 0.8]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores                                   RMSE  \\\n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.98-0.99             0.00    [243.0, 260.0, 261.0, 263.0, 264.0]   \n",
       "0          0.94-0.97             0.01    [420.0, 455.0, 481.0, 551.0, 598.0]   \n",
       "0          0.97-0.98             0.01    [450.0, 475.0, 527.0, 560.0, 587.0]   \n",
       "0          0.99-0.99             0.00    [389.0, 410.0, 411.0, 417.0, 461.0]   \n",
       "0          0.96-0.97             0.01    [425.0, 428.0, 435.0, 480.0, 511.0]   \n",
       "0          0.98-0.98             0.00    [308.0, 317.0, 323.0, 342.0, 343.0]   \n",
       "0          0.97-0.97             0.00    [661.0, 661.0, 667.0, 707.0, 725.0]   \n",
       "0          0.97-0.98             0.00    [411.0, 444.0, 469.0, 476.0, 493.0]   \n",
       "0          0.98-0.98             0.00    [348.0, 350.0, 371.0, 384.0, 387.0]   \n",
       "0          0.98-0.98             0.00    [326.0, 327.0, 330.0, 336.0, 348.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 754.0, 759.0, 761.0]   \n",
       "0          0.93-0.94             0.01    [823.0, 824.0, 825.0, 826.0, 831.0]   \n",
       "0          0.94-0.95             0.01    [747.0, 750.0, 753.0, 759.0, 761.0]   \n",
       "0          0.99-0.99             0.00    [327.0, 327.0, 331.0, 334.0, 334.0]   \n",
       "0          0.98-0.99             0.01    [382.0, 387.0, 390.0, 396.0, 413.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 812.0, 813.0, 817.0, 818.0]   \n",
       "0          0.85-0.87             0.01    [863.0, 877.0, 878.0, 879.0, 886.0]   \n",
       "0          0.88-0.89             0.01    [806.0, 811.0, 812.0, 817.0, 817.0]   \n",
       "0          0.98-0.98             0.00    [351.0, 356.0, 361.0, 365.0, 369.0]   \n",
       "0          0.97-0.97             0.00    [403.0, 411.0, 419.0, 431.0, 435.0]   \n",
       "0          0.84-0.86             0.01    [880.0, 885.0, 912.0, 932.0, 968.0]   \n",
       "0          0.93-0.94             0.00    [604.0, 611.0, 625.0, 632.0, 649.0]   \n",
       "0          0.84-0.86             0.01    [880.0, 885.0, 909.0, 935.0, 954.0]   \n",
       "0          0.93-0.94             0.00    [604.0, 611.0, 625.0, 631.0, 651.0]   \n",
       "0          0.97-0.97             0.00    [392.0, 404.0, 406.0, 432.0, 432.0]   \n",
       "0          0.97-0.97             0.00    [387.0, 400.0, 406.0, 420.0, 423.0]   \n",
       "0          0.53-0.87             0.15  [888.0, 895.0, 968.0, 1440.0, 1649.0]   \n",
       "0          0.94-0.95             0.01    [271.0, 274.0, 276.0, 282.0, 282.0]   \n",
       "0          0.91-0.94             0.01    [449.0, 458.0, 477.0, 510.0, 538.0]   \n",
       "0           0.47-0.8             0.14    [521.0, 533.0, 575.0, 729.0, 887.0]   \n",
       "\n",
       "  Range of RMSE                                        MAE  \\\n",
       "0   747.0-761.0   [539.01, 544.88, 548.35, 548.62, 554.01]   \n",
       "0   243.0-264.0   [189.32, 191.26, 195.81, 199.95, 204.91]   \n",
       "0   420.0-598.0      [304.21, 326.6, 333.4, 333.8, 340.42]   \n",
       "0   450.0-587.0    [348.45, 360.18, 373.76, 402.8, 404.99]   \n",
       "0   389.0-461.0    [288.51, 303.81, 304.2, 305.83, 345.36]   \n",
       "0   425.0-511.0   [322.94, 332.13, 334.76, 347.04, 353.21]   \n",
       "0   308.0-343.0    [228.1, 238.39, 251.72, 253.29, 265.95]   \n",
       "0   661.0-725.0    [479.93, 502.99, 507.38, 510.57, 515.9]   \n",
       "0   411.0-493.0   [313.53, 319.11, 344.25, 361.63, 363.62]   \n",
       "0   348.0-387.0   [248.59, 249.59, 261.29, 261.74, 261.85]   \n",
       "0   326.0-348.0   [253.24, 253.97, 254.97, 257.17, 261.38]   \n",
       "0   747.0-761.0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   747.0-761.0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   823.0-831.0   [584.13, 588.87, 593.47, 595.88, 603.25]   \n",
       "0   747.0-761.0   [539.01, 544.88, 548.35, 548.61, 554.01]   \n",
       "0   327.0-334.0   [224.17, 224.43, 224.75, 225.25, 229.57]   \n",
       "0   382.0-413.0   [265.91, 272.71, 272.93, 273.94, 276.48]   \n",
       "0   806.0-817.0   [599.65, 603.74, 604.48, 606.87, 612.88]   \n",
       "0   806.0-818.0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   806.0-818.0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   863.0-886.0   [638.17, 643.96, 646.54, 646.91, 668.87]   \n",
       "0   806.0-817.0   [599.57, 603.69, 604.48, 606.85, 612.88]   \n",
       "0   351.0-369.0    [264.28, 264.31, 264.82, 267.54, 272.7]   \n",
       "0   403.0-435.0     [292.7, 303.9, 304.22, 304.31, 308.96]   \n",
       "0   880.0-968.0    [632.76, 639.1, 639.86, 666.64, 686.81]   \n",
       "0   604.0-649.0   [445.04, 453.04, 464.57, 466.71, 467.52]   \n",
       "0   880.0-954.0   [636.73, 637.26, 642.49, 676.06, 676.63]   \n",
       "0   604.0-651.0    [444.05, 453.76, 462.01, 463.62, 467.3]   \n",
       "0   392.0-432.0     [283.6, 292.89, 296.46, 300.2, 300.94]   \n",
       "0   387.0-423.0   [283.04, 293.27, 295.01, 299.56, 303.83]   \n",
       "0  888.0-1649.0  [675.77, 678.72, 681.47, 1289.21, 1333.7]   \n",
       "0   271.0-282.0    [211.21, 215.0, 217.17, 217.75, 218.49]   \n",
       "0   449.0-538.0   [347.72, 348.02, 352.54, 369.51, 393.18]   \n",
       "0   521.0-887.0   [383.34, 390.09, 415.22, 547.52, 703.45]   \n",
       "\n",
       "                          Range of MAE  \n",
       "0                        539.01-554.01  \n",
       "0                        189.32-204.91  \n",
       "0                        304.21-340.42  \n",
       "0                        348.45-404.99  \n",
       "0                        288.51-345.36  \n",
       "0                        322.94-353.21  \n",
       "0                         228.1-265.95  \n",
       "0                         479.93-515.9  \n",
       "0                        313.53-363.62  \n",
       "0                        248.59-261.85  \n",
       "0                        253.24-261.38  \n",
       "0                        538.52-553.62  \n",
       "0                        538.52-553.62  \n",
       "0                        584.13-603.25  \n",
       "0                        539.01-554.01  \n",
       "0                        224.17-229.57  \n",
       "0                        265.91-276.48  \n",
       "0                        599.65-612.88  \n",
       "0                        599.67-613.25  \n",
       "0                        599.67-613.25  \n",
       "0                        638.17-668.87  \n",
       "0                        599.57-612.88  \n",
       "0                         264.28-272.7  \n",
       "0                         292.7-308.96  \n",
       "0                        632.76-686.81  \n",
       "0                        445.04-467.52  \n",
       "0                        636.73-676.63  \n",
       "0                         444.05-467.3  \n",
       "0                         283.6-300.94  \n",
       "0                        283.04-303.83  \n",
       "0    675.77001953125-1333.699951171875  \n",
       "0                        211.21-218.49  \n",
       "0                        347.72-393.18  \n",
       "0  383.3399963378906-703.4500122070312  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Lets train and evaluate the LSTM with Cluster 1 Data\n",
    "train_cluster1=traindata[traindata.Cluster=='Cluster1']\n",
    "test_cluster1=test_hiddata[test_hiddata.Cluster=='Cluster1']\n",
    "\n",
    "X_train=train_cluster1.drop(columns=['Sales','Date','Store','Cluster']).values.astype('float32')\n",
    "X_test=test_cluster1.drop(columns=['Sales','Date','Store','Cluster']).values.astype('float32')\n",
    "\n",
    "y_train=train_cluster1.Sales.values.astype('float32')\n",
    "y_test=test_cluster1.Sales.values.astype('float32')\n",
    "\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "#Lets train and evaluate the LSTM model with Cluster 1 Data\n",
    "#Initialize Sequential model\n",
    "model_LSTM = Sequential()\n",
    "\n",
    "#First Hidden Layer\n",
    "model_LSTM.add(LSTM(50))\n",
    "model_LSTM.add(BatchNormalization())\n",
    "\n",
    "#Output Layer\n",
    "model_LSTM.add(Dense(1))\n",
    "\n",
    "#Compile the model\n",
    "model_LSTM.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#Train The model with Cross Validation\n",
    "approach='LSTM with Cluster1 Data'\n",
    "model_obj=model_LSTM\n",
    "model_name='LSTM'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "#Exporting the results to csv\n",
    "#df_model_selection.to_csv(\"Model_statistics-Until_LSTM\",index = False)\n",
    "\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 48s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 413.0]</td>\n",
       "      <td>382.0-413.0</td>\n",
       "      <td>[265.91, 272.71, 272.93, 273.94, 276.48]</td>\n",
       "      <td>265.91-276.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 411.0, 419.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.7, 303.9, 304.22, 304.31, 308.96]</td>\n",
       "      <td>292.7-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 912.0, 932.0, 968.0]</td>\n",
       "      <td>880.0-968.0</td>\n",
       "      <td>[632.76, 639.1, 639.86, 666.64, 686.81]</td>\n",
       "      <td>632.76-686.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 632.0, 649.0]</td>\n",
       "      <td>604.0-649.0</td>\n",
       "      <td>[445.04, 453.04, 464.57, 466.71, 467.52]</td>\n",
       "      <td>445.04-467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 909.0, 935.0, 954.0]</td>\n",
       "      <td>880.0-954.0</td>\n",
       "      <td>[636.73, 637.26, 642.49, 676.06, 676.63]</td>\n",
       "      <td>636.73-676.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 631.0, 651.0]</td>\n",
       "      <td>604.0-651.0</td>\n",
       "      <td>[444.05, 453.76, 462.01, 463.62, 467.3]</td>\n",
       "      <td>444.05-467.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[392.0, 404.0, 406.0, 432.0, 432.0]</td>\n",
       "      <td>392.0-432.0</td>\n",
       "      <td>[283.6, 292.89, 296.46, 300.2, 300.94]</td>\n",
       "      <td>283.6-300.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>XGBoost RFRegressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[387.0, 400.0, 406.0, 420.0, 423.0]</td>\n",
       "      <td>387.0-423.0</td>\n",
       "      <td>[283.04, 293.27, 295.01, 299.56, 303.83]</td>\n",
       "      <td>283.04-303.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.53, 0.64, 0.83, 0.86, 0.87]</td>\n",
       "      <td>0.53-0.87</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[888.0, 895.0, 968.0, 1440.0, 1649.0]</td>\n",
       "      <td>888.0-1649.0</td>\n",
       "      <td>[675.77, 678.72, 681.47, 1289.21, 1333.7]</td>\n",
       "      <td>675.77001953125-1333.699951171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster1 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.94, 0.94, 0.95, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[271.0, 274.0, 276.0, 282.0, 282.0]</td>\n",
       "      <td>271.0-282.0</td>\n",
       "      <td>[211.21, 215.0, 217.17, 217.75, 218.49]</td>\n",
       "      <td>211.21-218.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster2 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.91, 0.92, 0.92, 0.94, 0.94]</td>\n",
       "      <td>0.91-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[449.0, 458.0, 477.0, 510.0, 538.0]</td>\n",
       "      <td>449.0-538.0</td>\n",
       "      <td>[347.72, 348.02, 352.54, 369.51, 393.18]</td>\n",
       "      <td>347.72-393.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM with Cluster1 Data</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.47, 0.62, 0.76, 0.8, 0.8]</td>\n",
       "      <td>0.47-0.8</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[521.0, 533.0, 575.0, 729.0, 887.0]</td>\n",
       "      <td>521.0-887.0</td>\n",
       "      <td>[383.34, 390.09, 415.22, 547.52, 703.45]</td>\n",
       "      <td>383.3399963378906-703.4500122070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM with Cluster2 Data</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[-2.84, 0.54, 0.59, 0.6, 0.64]</td>\n",
       "      <td>-2.84-0.64</td>\n",
       "      <td>1.54</td>\n",
       "      <td>[1060.0, 1123.0, 1133.0, 1176.0, 3661.0]</td>\n",
       "      <td>1060.0-3661.0</td>\n",
       "      <td>[809.57, 825.6, 864.01, 873.12, 3358.85]</td>\n",
       "      <td>809.5700073242188-3358.85009765625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0                                               LSTM   \n",
       "0                 Model Training with  Cluster1 Data   \n",
       "0                 Model Training with  Cluster2 Data   \n",
       "0                            LSTM with Cluster1 Data   \n",
       "0                            LSTM with Cluster2 Data   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Random Forest Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                        XGBoost RFRegressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                                       LSTM  [0.53, 0.64, 0.83, 0.86, 0.87]   \n",
       "0                          XGBoost Regressor  [0.94, 0.94, 0.95, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.91, 0.92, 0.92, 0.94, 0.94]   \n",
       "0                                       LSTM    [0.47, 0.62, 0.76, 0.8, 0.8]   \n",
       "0                                       LSTM  [-2.84, 0.54, 0.59, 0.6, 0.64]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores  \\\n",
       "0          0.94-0.95             0.01   \n",
       "0          0.98-0.99             0.00   \n",
       "0          0.94-0.97             0.01   \n",
       "0          0.97-0.98             0.01   \n",
       "0          0.99-0.99             0.00   \n",
       "0          0.96-0.97             0.01   \n",
       "0          0.98-0.98             0.00   \n",
       "0          0.97-0.97             0.00   \n",
       "0          0.97-0.98             0.00   \n",
       "0          0.98-0.98             0.00   \n",
       "0          0.98-0.98             0.00   \n",
       "0          0.94-0.95             0.01   \n",
       "0          0.94-0.95             0.01   \n",
       "0          0.93-0.94             0.01   \n",
       "0          0.94-0.95             0.01   \n",
       "0          0.99-0.99             0.00   \n",
       "0          0.98-0.99             0.01   \n",
       "0          0.88-0.89             0.01   \n",
       "0          0.88-0.89             0.01   \n",
       "0          0.88-0.89             0.01   \n",
       "0          0.85-0.87             0.01   \n",
       "0          0.88-0.89             0.01   \n",
       "0          0.98-0.98             0.00   \n",
       "0          0.97-0.97             0.00   \n",
       "0          0.84-0.86             0.01   \n",
       "0          0.93-0.94             0.00   \n",
       "0          0.84-0.86             0.01   \n",
       "0          0.93-0.94             0.00   \n",
       "0          0.97-0.97             0.00   \n",
       "0          0.97-0.97             0.00   \n",
       "0          0.53-0.87             0.15   \n",
       "0          0.94-0.95             0.01   \n",
       "0          0.91-0.94             0.01   \n",
       "0           0.47-0.8             0.14   \n",
       "0         -2.84-0.64             1.54   \n",
       "\n",
       "                                       RMSE  Range of RMSE  \\\n",
       "0       [747.0, 750.0, 753.0, 759.0, 761.0]    747.0-761.0   \n",
       "0       [243.0, 260.0, 261.0, 263.0, 264.0]    243.0-264.0   \n",
       "0       [420.0, 455.0, 481.0, 551.0, 598.0]    420.0-598.0   \n",
       "0       [450.0, 475.0, 527.0, 560.0, 587.0]    450.0-587.0   \n",
       "0       [389.0, 410.0, 411.0, 417.0, 461.0]    389.0-461.0   \n",
       "0       [425.0, 428.0, 435.0, 480.0, 511.0]    425.0-511.0   \n",
       "0       [308.0, 317.0, 323.0, 342.0, 343.0]    308.0-343.0   \n",
       "0       [661.0, 661.0, 667.0, 707.0, 725.0]    661.0-725.0   \n",
       "0       [411.0, 444.0, 469.0, 476.0, 493.0]    411.0-493.0   \n",
       "0       [348.0, 350.0, 371.0, 384.0, 387.0]    348.0-387.0   \n",
       "0       [326.0, 327.0, 330.0, 336.0, 348.0]    326.0-348.0   \n",
       "0       [747.0, 750.0, 754.0, 759.0, 761.0]    747.0-761.0   \n",
       "0       [747.0, 750.0, 754.0, 759.0, 761.0]    747.0-761.0   \n",
       "0       [823.0, 824.0, 825.0, 826.0, 831.0]    823.0-831.0   \n",
       "0       [747.0, 750.0, 753.0, 759.0, 761.0]    747.0-761.0   \n",
       "0       [327.0, 327.0, 331.0, 334.0, 334.0]    327.0-334.0   \n",
       "0       [382.0, 387.0, 390.0, 396.0, 413.0]    382.0-413.0   \n",
       "0       [806.0, 811.0, 812.0, 817.0, 817.0]    806.0-817.0   \n",
       "0       [806.0, 812.0, 813.0, 817.0, 818.0]    806.0-818.0   \n",
       "0       [806.0, 812.0, 813.0, 817.0, 818.0]    806.0-818.0   \n",
       "0       [863.0, 877.0, 878.0, 879.0, 886.0]    863.0-886.0   \n",
       "0       [806.0, 811.0, 812.0, 817.0, 817.0]    806.0-817.0   \n",
       "0       [351.0, 356.0, 361.0, 365.0, 369.0]    351.0-369.0   \n",
       "0       [403.0, 411.0, 419.0, 431.0, 435.0]    403.0-435.0   \n",
       "0       [880.0, 885.0, 912.0, 932.0, 968.0]    880.0-968.0   \n",
       "0       [604.0, 611.0, 625.0, 632.0, 649.0]    604.0-649.0   \n",
       "0       [880.0, 885.0, 909.0, 935.0, 954.0]    880.0-954.0   \n",
       "0       [604.0, 611.0, 625.0, 631.0, 651.0]    604.0-651.0   \n",
       "0       [392.0, 404.0, 406.0, 432.0, 432.0]    392.0-432.0   \n",
       "0       [387.0, 400.0, 406.0, 420.0, 423.0]    387.0-423.0   \n",
       "0     [888.0, 895.0, 968.0, 1440.0, 1649.0]   888.0-1649.0   \n",
       "0       [271.0, 274.0, 276.0, 282.0, 282.0]    271.0-282.0   \n",
       "0       [449.0, 458.0, 477.0, 510.0, 538.0]    449.0-538.0   \n",
       "0       [521.0, 533.0, 575.0, 729.0, 887.0]    521.0-887.0   \n",
       "0  [1060.0, 1123.0, 1133.0, 1176.0, 3661.0]  1060.0-3661.0   \n",
       "\n",
       "                                         MAE  \\\n",
       "0   [539.01, 544.88, 548.35, 548.62, 554.01]   \n",
       "0   [189.32, 191.26, 195.81, 199.95, 204.91]   \n",
       "0      [304.21, 326.6, 333.4, 333.8, 340.42]   \n",
       "0    [348.45, 360.18, 373.76, 402.8, 404.99]   \n",
       "0    [288.51, 303.81, 304.2, 305.83, 345.36]   \n",
       "0   [322.94, 332.13, 334.76, 347.04, 353.21]   \n",
       "0    [228.1, 238.39, 251.72, 253.29, 265.95]   \n",
       "0    [479.93, 502.99, 507.38, 510.57, 515.9]   \n",
       "0   [313.53, 319.11, 344.25, 361.63, 363.62]   \n",
       "0   [248.59, 249.59, 261.29, 261.74, 261.85]   \n",
       "0   [253.24, 253.97, 254.97, 257.17, 261.38]   \n",
       "0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   [584.13, 588.87, 593.47, 595.88, 603.25]   \n",
       "0   [539.01, 544.88, 548.35, 548.61, 554.01]   \n",
       "0   [224.17, 224.43, 224.75, 225.25, 229.57]   \n",
       "0   [265.91, 272.71, 272.93, 273.94, 276.48]   \n",
       "0   [599.65, 603.74, 604.48, 606.87, 612.88]   \n",
       "0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   [638.17, 643.96, 646.54, 646.91, 668.87]   \n",
       "0   [599.57, 603.69, 604.48, 606.85, 612.88]   \n",
       "0    [264.28, 264.31, 264.82, 267.54, 272.7]   \n",
       "0     [292.7, 303.9, 304.22, 304.31, 308.96]   \n",
       "0    [632.76, 639.1, 639.86, 666.64, 686.81]   \n",
       "0   [445.04, 453.04, 464.57, 466.71, 467.52]   \n",
       "0   [636.73, 637.26, 642.49, 676.06, 676.63]   \n",
       "0    [444.05, 453.76, 462.01, 463.62, 467.3]   \n",
       "0     [283.6, 292.89, 296.46, 300.2, 300.94]   \n",
       "0   [283.04, 293.27, 295.01, 299.56, 303.83]   \n",
       "0  [675.77, 678.72, 681.47, 1289.21, 1333.7]   \n",
       "0    [211.21, 215.0, 217.17, 217.75, 218.49]   \n",
       "0   [347.72, 348.02, 352.54, 369.51, 393.18]   \n",
       "0   [383.34, 390.09, 415.22, 547.52, 703.45]   \n",
       "0   [809.57, 825.6, 864.01, 873.12, 3358.85]   \n",
       "\n",
       "                          Range of MAE  \n",
       "0                        539.01-554.01  \n",
       "0                        189.32-204.91  \n",
       "0                        304.21-340.42  \n",
       "0                        348.45-404.99  \n",
       "0                        288.51-345.36  \n",
       "0                        322.94-353.21  \n",
       "0                         228.1-265.95  \n",
       "0                         479.93-515.9  \n",
       "0                        313.53-363.62  \n",
       "0                        248.59-261.85  \n",
       "0                        253.24-261.38  \n",
       "0                        538.52-553.62  \n",
       "0                        538.52-553.62  \n",
       "0                        584.13-603.25  \n",
       "0                        539.01-554.01  \n",
       "0                        224.17-229.57  \n",
       "0                        265.91-276.48  \n",
       "0                        599.65-612.88  \n",
       "0                        599.67-613.25  \n",
       "0                        599.67-613.25  \n",
       "0                        638.17-668.87  \n",
       "0                        599.57-612.88  \n",
       "0                         264.28-272.7  \n",
       "0                         292.7-308.96  \n",
       "0                        632.76-686.81  \n",
       "0                        445.04-467.52  \n",
       "0                        636.73-676.63  \n",
       "0                         444.05-467.3  \n",
       "0                         283.6-300.94  \n",
       "0                        283.04-303.83  \n",
       "0    675.77001953125-1333.699951171875  \n",
       "0                        211.21-218.49  \n",
       "0                        347.72-393.18  \n",
       "0  383.3399963378906-703.4500122070312  \n",
       "0   809.5700073242188-3358.85009765625  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Lets train and evaluate the LSTM with Cluster 2 Data\n",
    "train_cluster2=traindata[traindata.Cluster=='Cluster2']\n",
    "test_cluster2=test_hiddata[test_hiddata.Cluster=='Cluster2']\n",
    "\n",
    "X_train=train_cluster2.drop(columns=['Sales','Date','Store','Cluster']).values.astype('float32')\n",
    "X_test=test_cluster2.drop(columns=['Sales','Date','Store','Cluster']).values.astype('float32')\n",
    "\n",
    "y_train=train_cluster2.Sales.values.astype('float32')\n",
    "y_test=test_cluster2.Sales.values.astype('float32')\n",
    "\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "#Lets train and evaluate the LSTM model with Cluster 1 Data\n",
    "#Initialize Sequential model\n",
    "model_LSTM = Sequential()\n",
    "\n",
    "#Input Layer and Normalize input data\n",
    "#model_LSTM.add(LSTM(50,return_sequences=True))\n",
    "#model_LSTM.add(BatchNormalization())\n",
    "\n",
    "#First Hidden Layer\n",
    "model_LSTM.add(LSTM(50))\n",
    "model_LSTM.add(BatchNormalization())\n",
    "\n",
    "#Output Layer\n",
    "model_LSTM.add(Dense(1))\n",
    "\n",
    "#Compile the model\n",
    "model_LSTM.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#Train The model with Cross Validation\n",
    "approach='LSTM with Cluster2 Data'\n",
    "model_obj=model_LSTM\n",
    "model_name='LSTM'\n",
    "#model_traintest(model_obj, model_name, approach,X_train,y_train,X_test,y_test)\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "#Exporting the results to csv\n",
    "df_model_selection.to_csv(\"Model_statistics_Upto_WK3_Tasks\",index = False)\n",
    "\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation after retraining of XGBoost and LSTM with Cluster1 and Cluster Data\n",
    "\n",
    "    It was observed that \n",
    "    1.There is no performance gain from LSTM model when trained with Cluster1 or Cluster2 data individually \n",
    "    2. XGBoost Regressor has shown improvement when trained with Cluster data however this is still not the best performance\n",
    "    3. The best performing model is still XGBoost Regressor with without cluster.(95%) followed by Gradiant Boosting Regressor(94%) followed by  XGBoost Regressor with cluster1 data followed by Ensemble Technique(88%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Task: Week 4\n",
    "\n",
    "**Applying ANN:**\n",
    "\n",
    "    1.     Use ANN (Artificial Neural Network) to predict Store Sales.\n",
    "       a)    Fine-tune number of layers,\n",
    "       b)    Number of Neurons in each layers .\n",
    "       c)    Experiment in batch-size.\n",
    "       d)    Experiment with number of epochs. Carefully observe the loss and accuracy? What are the observations?\n",
    "       e)    Play with different  Learning Rate  variants of Gradient Descent like Adam, SGD, RMS-prop.\n",
    "       f)    Which activation performs best for this use case and why?\n",
    "       g)    Check how it performed in the dataset, calculate RMSE.\n",
    "       \n",
    "    2. Use Dropout for ANN and find the optimum number of clusters (clusters formed considering the features: sales and \n",
    "    customer visits). Compare model performance with traditional ML based prediction models. \n",
    "    \n",
    "    3. Find the best setting of neural net that minimizes the loss and can predict the sales best. Use techniques like Grid\n",
    "       search, cross-validation and Random search.\n",
    "\n",
    "\n",
    "\n",
    "### Code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7550 7550 270 270\n"
     ]
    }
   ],
   "source": [
    "#Prepare Data\n",
    "traindata=traindata_init[(traindata_init.Sales !=0)&(traindata_init.Store.isin(storeList))]\n",
    "traindata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "test_hiddata=test_hiddata_init[(test_hiddata_init.Sales !=0)&(test_hiddata_init.Store.isin(storeList))]\n",
    "test_hiddata.reset_index(drop=True,inplace=True)\n",
    "\n",
    "X_train=traindata.drop(columns=['Sales','Date','Store']).values.astype('float32')\n",
    "X_test=test_hiddata.drop(columns=['Sales','Date','Store']).values.astype('float32')\n",
    "#X_train=SC.fit_transform(X_train) # Perform feature scaling on train  data\n",
    "#X_test=SC.fit_transform(X_test) # Perform feature scaling on test data\n",
    "\n",
    "y_train=traindata.Sales.values.astype('float32')\n",
    "y_test=test_hiddata.Sales.values.astype('float32')\n",
    "\n",
    "\n",
    "print(len(X_train),len(y_train), len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7550, 9), (270, 9))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "#Initialize Sequential model\n",
    "model_ANN = tf.keras.models.Sequential()\n",
    "#Input Layer\n",
    "model_ANN.add(tf.keras.layers.Reshape((9,),input_shape=(9,)))\n",
    "#Normalize the data\n",
    "model_ANN.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 1st hidden layer\n",
    "model_ANN.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "#Dropout layer\n",
    "#model_ANN.add(tf.keras.layers.Dropout(0.5))\n",
    "#Normalize the data\n",
    "model_ANN.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 2nd hidden layer\n",
    "model_ANN.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "#Dropout layer\n",
    "#model_ANN.add(tf.keras.layers.Dropout(0.4))\n",
    "#Normalize the data\n",
    "model_ANN.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 3rd hidden layer\n",
    "model_ANN.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "#Dropout layer\n",
    "#model_ANN.add(tf.keras.layers.Dropout(0.3))\n",
    "#Normalize the data\n",
    "model_ANN.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 4th hidden layer\n",
    "#model_ANN.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "#Dropout layer\n",
    "#model_ANN.add(tf.keras.layers.Dropout(0.3))\n",
    "#Normalize the data\n",
    "#model_ANN.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model_ANN.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "#Compile the model\n",
    "model_ANN.compile(optimizer='adam', loss='mse')\n",
    "#model_ANN.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 25s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>r2 Scores</th>\n",
       "      <th>Range of r2 Scores</th>\n",
       "      <th>SD of r2 Scores</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Range of RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Range of MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.62, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store1 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[243.0, 260.0, 261.0, 263.0, 264.0]</td>\n",
       "      <td>243.0-264.0</td>\n",
       "      <td>[189.32, 191.26, 195.81, 199.95, 204.91]</td>\n",
       "      <td>189.32-204.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store2 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.94, 0.94, 0.96, 0.96, 0.97]</td>\n",
       "      <td>0.94-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[420.0, 455.0, 481.0, 551.0, 598.0]</td>\n",
       "      <td>420.0-598.0</td>\n",
       "      <td>[304.21, 326.6, 333.4, 333.8, 340.42]</td>\n",
       "      <td>304.21-340.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store3 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.98, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[450.0, 475.0, 527.0, 560.0, 587.0]</td>\n",
       "      <td>450.0-587.0</td>\n",
       "      <td>[348.45, 360.18, 373.76, 402.8, 404.99]</td>\n",
       "      <td>348.45-404.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store4 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[389.0, 410.0, 411.0, 417.0, 461.0]</td>\n",
       "      <td>389.0-461.0</td>\n",
       "      <td>[288.51, 303.81, 304.2, 305.83, 345.36]</td>\n",
       "      <td>288.51-345.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store5 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.96, 0.96, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.96-0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[425.0, 428.0, 435.0, 480.0, 511.0]</td>\n",
       "      <td>425.0-511.0</td>\n",
       "      <td>[322.94, 332.13, 334.76, 347.04, 353.21]</td>\n",
       "      <td>322.94-353.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store6 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[308.0, 317.0, 323.0, 342.0, 343.0]</td>\n",
       "      <td>308.0-343.0</td>\n",
       "      <td>[228.1, 238.39, 251.72, 253.29, 265.95]</td>\n",
       "      <td>228.1-265.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store7 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[661.0, 661.0, 667.0, 707.0, 725.0]</td>\n",
       "      <td>661.0-725.0</td>\n",
       "      <td>[479.93, 502.99, 507.38, 510.57, 515.9]</td>\n",
       "      <td>479.93-515.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store8 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.98]</td>\n",
       "      <td>0.97-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[411.0, 444.0, 469.0, 476.0, 493.0]</td>\n",
       "      <td>411.0-493.0</td>\n",
       "      <td>[313.53, 319.11, 344.25, 361.63, 363.62]</td>\n",
       "      <td>313.53-363.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store9 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[348.0, 350.0, 371.0, 384.0, 387.0]</td>\n",
       "      <td>348.0-387.0</td>\n",
       "      <td>[248.59, 249.59, 261.29, 261.74, 261.85]</td>\n",
       "      <td>248.59-261.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with Store10 Data</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[326.0, 327.0, 330.0, 336.0, 348.0]</td>\n",
       "      <td>326.0-348.0</td>\n",
       "      <td>[253.24, 253.97, 254.97, 257.17, 261.38]</td>\n",
       "      <td>253.24-261.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 754.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[538.52, 544.45, 547.65, 548.19, 553.62]</td>\n",
       "      <td>538.52-553.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.94, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[823.0, 824.0, 825.0, 826.0, 831.0]</td>\n",
       "      <td>823.0-831.0</td>\n",
       "      <td>[584.13, 588.87, 593.47, 595.88, 603.25]</td>\n",
       "      <td>584.13-603.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.94, 0.94, 0.94, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[747.0, 750.0, 753.0, 759.0, 761.0]</td>\n",
       "      <td>747.0-761.0</td>\n",
       "      <td>[539.01, 544.88, 548.35, 548.61, 554.01]</td>\n",
       "      <td>539.01-554.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.99, 0.99, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.99-0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[327.0, 327.0, 331.0, 334.0, 334.0]</td>\n",
       "      <td>327.0-334.0</td>\n",
       "      <td>[224.17, 224.43, 224.75, 225.25, 229.57]</td>\n",
       "      <td>224.17-229.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.99, 0.99, 0.99]</td>\n",
       "      <td>0.98-0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[382.0, 387.0, 390.0, 396.0, 413.0]</td>\n",
       "      <td>382.0-413.0</td>\n",
       "      <td>[265.91, 272.71, 272.93, 273.94, 276.48]</td>\n",
       "      <td>265.91-276.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.65, 603.74, 604.48, 606.87, 612.88]</td>\n",
       "      <td>599.65-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Lasso</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- Ridge</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 812.0, 813.0, 817.0, 818.0]</td>\n",
       "      <td>806.0-818.0</td>\n",
       "      <td>[599.67, 604.08, 604.57, 606.86, 613.25]</td>\n",
       "      <td>599.67-613.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Regularized Linear Regression- ElasticNet</td>\n",
       "      <td>[0.85, 0.87, 0.87, 0.87, 0.87]</td>\n",
       "      <td>0.85-0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[863.0, 877.0, 878.0, 879.0, 886.0]</td>\n",
       "      <td>863.0-886.0</td>\n",
       "      <td>[638.17, 643.96, 646.54, 646.91, 668.87]</td>\n",
       "      <td>638.17-668.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble Learning</td>\n",
       "      <td>Ensemble Learner LR+RegLR</td>\n",
       "      <td>[0.88, 0.88, 0.88, 0.89, 0.89]</td>\n",
       "      <td>0.88-0.89</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[806.0, 811.0, 812.0, 817.0, 817.0]</td>\n",
       "      <td>806.0-817.0</td>\n",
       "      <td>[599.57, 603.69, 604.48, 606.85, 612.88]</td>\n",
       "      <td>599.57-612.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.98, 0.98, 0.98, 0.98, 0.98]</td>\n",
       "      <td>0.98-0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[351.0, 356.0, 361.0, 365.0, 369.0]</td>\n",
       "      <td>351.0-369.0</td>\n",
       "      <td>[264.28, 264.31, 264.82, 267.54, 272.7]</td>\n",
       "      <td>264.28-272.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  10 Stores Data with Open ...</td>\n",
       "      <td>Gradiant Boosting Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[403.0, 411.0, 419.0, 431.0, 435.0]</td>\n",
       "      <td>403.0-435.0</td>\n",
       "      <td>[292.7, 303.9, 304.22, 304.31, 308.96]</td>\n",
       "      <td>292.7-308.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 912.0, 932.0, 968.0]</td>\n",
       "      <td>880.0-968.0</td>\n",
       "      <td>[632.76, 639.1, 639.86, 666.64, 686.81]</td>\n",
       "      <td>632.76-686.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 632.0, 649.0]</td>\n",
       "      <td>604.0-649.0</td>\n",
       "      <td>[445.04, 453.04, 464.57, 466.71, 467.52]</td>\n",
       "      <td>445.04-467.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>[0.84, 0.85, 0.86, 0.86, 0.86]</td>\n",
       "      <td>0.84-0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[880.0, 885.0, 909.0, 935.0, 954.0]</td>\n",
       "      <td>880.0-954.0</td>\n",
       "      <td>[636.73, 637.26, 642.49, 676.06, 676.63]</td>\n",
       "      <td>636.73-676.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Kernel PCA</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>[0.93, 0.93, 0.93, 0.93, 0.94]</td>\n",
       "      <td>0.93-0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[604.0, 611.0, 625.0, 631.0, 651.0]</td>\n",
       "      <td>604.0-651.0</td>\n",
       "      <td>[444.05, 453.76, 462.01, 463.62, 467.3]</td>\n",
       "      <td>444.05-467.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[392.0, 404.0, 406.0, 432.0, 432.0]</td>\n",
       "      <td>392.0-432.0</td>\n",
       "      <td>[283.6, 292.89, 296.46, 300.2, 300.94]</td>\n",
       "      <td>283.6-300.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training after Hyperparameter Tuning</td>\n",
       "      <td>XGBoost RFRegressor</td>\n",
       "      <td>[0.97, 0.97, 0.97, 0.97, 0.97]</td>\n",
       "      <td>0.97-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[387.0, 400.0, 406.0, 420.0, 423.0]</td>\n",
       "      <td>387.0-423.0</td>\n",
       "      <td>[283.04, 293.27, 295.01, 299.56, 303.83]</td>\n",
       "      <td>283.04-303.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.53, 0.64, 0.83, 0.86, 0.87]</td>\n",
       "      <td>0.53-0.87</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[888.0, 895.0, 968.0, 1440.0, 1649.0]</td>\n",
       "      <td>888.0-1649.0</td>\n",
       "      <td>[675.77, 678.72, 681.47, 1289.21, 1333.7]</td>\n",
       "      <td>675.77001953125-1333.699951171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster1 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.94, 0.94, 0.95, 0.95, 0.95]</td>\n",
       "      <td>0.94-0.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[271.0, 274.0, 276.0, 282.0, 282.0]</td>\n",
       "      <td>271.0-282.0</td>\n",
       "      <td>[211.21, 215.0, 217.17, 217.75, 218.49]</td>\n",
       "      <td>211.21-218.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Training with  Cluster2 Data</td>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>[0.91, 0.92, 0.92, 0.94, 0.94]</td>\n",
       "      <td>0.91-0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[449.0, 458.0, 477.0, 510.0, 538.0]</td>\n",
       "      <td>449.0-538.0</td>\n",
       "      <td>[347.72, 348.02, 352.54, 369.51, 393.18]</td>\n",
       "      <td>347.72-393.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM with Cluster1 Data</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[0.47, 0.62, 0.76, 0.8, 0.8]</td>\n",
       "      <td>0.47-0.8</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[521.0, 533.0, 575.0, 729.0, 887.0]</td>\n",
       "      <td>521.0-887.0</td>\n",
       "      <td>[383.34, 390.09, 415.22, 547.52, 703.45]</td>\n",
       "      <td>383.3399963378906-703.4500122070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM with Cluster2 Data</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>[-2.84, 0.54, 0.59, 0.6, 0.64]</td>\n",
       "      <td>-2.84-0.64</td>\n",
       "      <td>1.54</td>\n",
       "      <td>[1060.0, 1123.0, 1133.0, 1176.0, 3661.0]</td>\n",
       "      <td>1060.0-3661.0</td>\n",
       "      <td>[809.57, 825.6, 864.01, 873.12, 3358.85]</td>\n",
       "      <td>809.5700073242188-3358.85009765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN-3HidLayer-Adam-Epoch150-batchsize32</td>\n",
       "      <td>ANN</td>\n",
       "      <td>[0.85, 0.87, 0.88, 0.89, 0.92]</td>\n",
       "      <td>0.85-0.92</td>\n",
       "      <td>0.03</td>\n",
       "      <td>[695.0, 772.0, 828.0, 869.0, 954.0]</td>\n",
       "      <td>695.0-954.0</td>\n",
       "      <td>[524.91, 529.49, 533.47, 547.79, 549.7]</td>\n",
       "      <td>524.9099731445312-549.7000122070312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Approach  \\\n",
       "0                Model Training with  10 Stores Data   \n",
       "0                    Model Training with Store1 Data   \n",
       "0                    Model Training with Store2 Data   \n",
       "0                    Model Training with Store3 Data   \n",
       "0                    Model Training with Store4 Data   \n",
       "0                    Model Training with Store5 Data   \n",
       "0                    Model Training with Store6 Data   \n",
       "0                    Model Training with Store7 Data   \n",
       "0                    Model Training with Store8 Data   \n",
       "0                    Model Training with Store9 Data   \n",
       "0                   Model Training with Store10 Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                                  Ensemble Learning   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0                Model Training with  10 Stores Data   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                                  Ensemble Learning   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0  Model Training with  10 Stores Data with Open ...   \n",
       "0                            Model Training with PCA   \n",
       "0                            Model Training with PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0                    Model Training with  Kernel PCA   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0         Model Training after Hyperparameter Tuning   \n",
       "0                                               LSTM   \n",
       "0                 Model Training with  Cluster1 Data   \n",
       "0                 Model Training with  Cluster2 Data   \n",
       "0                            LSTM with Cluster1 Data   \n",
       "0                            LSTM with Cluster2 Data   \n",
       "0            ANN-3HidLayer-Adam-Epoch150-batchsize32   \n",
       "\n",
       "                                  Model Name                       r2 Scores  \\\n",
       "0                          Linear Regression  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.99]   \n",
       "0                          Linear Regression  [0.94, 0.94, 0.96, 0.96, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.96, 0.96, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                          Linear Regression  [0.97, 0.97, 0.97, 0.97, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                          Linear Regression  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0       Regularized Linear Regression- Lasso  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0       Regularized Linear Regression- Ridge  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.93, 0.93, 0.93, 0.94, 0.94]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.94, 0.94, 0.94, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.99, 0.99, 0.99, 0.99, 0.99]   \n",
       "0                Gradiant Boosting Regressor  [0.98, 0.98, 0.99, 0.99, 0.99]   \n",
       "0                          Linear Regression  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Lasso  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0       Regularized Linear Regression- Ridge  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0  Regularized Linear Regression- ElasticNet  [0.85, 0.87, 0.87, 0.87, 0.87]   \n",
       "0                  Ensemble Learner LR+RegLR  [0.88, 0.88, 0.88, 0.89, 0.89]   \n",
       "0                          XGBoost Regressor  [0.98, 0.98, 0.98, 0.98, 0.98]   \n",
       "0                Gradiant Boosting Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Decision Tree Regressor  [0.84, 0.85, 0.86, 0.86, 0.86]   \n",
       "0                     RandomForest Regressor  [0.93, 0.93, 0.93, 0.93, 0.94]   \n",
       "0                    Random Forest Regressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                        XGBoost RFRegressor  [0.97, 0.97, 0.97, 0.97, 0.97]   \n",
       "0                                       LSTM  [0.53, 0.64, 0.83, 0.86, 0.87]   \n",
       "0                          XGBoost Regressor  [0.94, 0.94, 0.95, 0.95, 0.95]   \n",
       "0                          XGBoost Regressor  [0.91, 0.92, 0.92, 0.94, 0.94]   \n",
       "0                                       LSTM    [0.47, 0.62, 0.76, 0.8, 0.8]   \n",
       "0                                       LSTM  [-2.84, 0.54, 0.59, 0.6, 0.64]   \n",
       "0                                        ANN  [0.85, 0.87, 0.88, 0.89, 0.92]   \n",
       "\n",
       "  Range of r2 Scores  SD of r2 Scores  \\\n",
       "0          0.94-0.95             0.01   \n",
       "0          0.98-0.99             0.00   \n",
       "0          0.94-0.97             0.01   \n",
       "0          0.97-0.98             0.01   \n",
       "0          0.99-0.99             0.00   \n",
       "0          0.96-0.97             0.01   \n",
       "0          0.98-0.98             0.00   \n",
       "0          0.97-0.97             0.00   \n",
       "0          0.97-0.98             0.00   \n",
       "0          0.98-0.98             0.00   \n",
       "0          0.98-0.98             0.00   \n",
       "0          0.94-0.95             0.01   \n",
       "0          0.94-0.95             0.01   \n",
       "0          0.93-0.94             0.01   \n",
       "0          0.94-0.95             0.01   \n",
       "0          0.99-0.99             0.00   \n",
       "0          0.98-0.99             0.01   \n",
       "0          0.88-0.89             0.01   \n",
       "0          0.88-0.89             0.01   \n",
       "0          0.88-0.89             0.01   \n",
       "0          0.85-0.87             0.01   \n",
       "0          0.88-0.89             0.01   \n",
       "0          0.98-0.98             0.00   \n",
       "0          0.97-0.97             0.00   \n",
       "0          0.84-0.86             0.01   \n",
       "0          0.93-0.94             0.00   \n",
       "0          0.84-0.86             0.01   \n",
       "0          0.93-0.94             0.00   \n",
       "0          0.97-0.97             0.00   \n",
       "0          0.97-0.97             0.00   \n",
       "0          0.53-0.87             0.15   \n",
       "0          0.94-0.95             0.01   \n",
       "0          0.91-0.94             0.01   \n",
       "0           0.47-0.8             0.14   \n",
       "0         -2.84-0.64             1.54   \n",
       "0          0.85-0.92             0.03   \n",
       "\n",
       "                                       RMSE  Range of RMSE  \\\n",
       "0       [747.0, 750.0, 753.0, 759.0, 761.0]    747.0-761.0   \n",
       "0       [243.0, 260.0, 261.0, 263.0, 264.0]    243.0-264.0   \n",
       "0       [420.0, 455.0, 481.0, 551.0, 598.0]    420.0-598.0   \n",
       "0       [450.0, 475.0, 527.0, 560.0, 587.0]    450.0-587.0   \n",
       "0       [389.0, 410.0, 411.0, 417.0, 461.0]    389.0-461.0   \n",
       "0       [425.0, 428.0, 435.0, 480.0, 511.0]    425.0-511.0   \n",
       "0       [308.0, 317.0, 323.0, 342.0, 343.0]    308.0-343.0   \n",
       "0       [661.0, 661.0, 667.0, 707.0, 725.0]    661.0-725.0   \n",
       "0       [411.0, 444.0, 469.0, 476.0, 493.0]    411.0-493.0   \n",
       "0       [348.0, 350.0, 371.0, 384.0, 387.0]    348.0-387.0   \n",
       "0       [326.0, 327.0, 330.0, 336.0, 348.0]    326.0-348.0   \n",
       "0       [747.0, 750.0, 754.0, 759.0, 761.0]    747.0-761.0   \n",
       "0       [747.0, 750.0, 754.0, 759.0, 761.0]    747.0-761.0   \n",
       "0       [823.0, 824.0, 825.0, 826.0, 831.0]    823.0-831.0   \n",
       "0       [747.0, 750.0, 753.0, 759.0, 761.0]    747.0-761.0   \n",
       "0       [327.0, 327.0, 331.0, 334.0, 334.0]    327.0-334.0   \n",
       "0       [382.0, 387.0, 390.0, 396.0, 413.0]    382.0-413.0   \n",
       "0       [806.0, 811.0, 812.0, 817.0, 817.0]    806.0-817.0   \n",
       "0       [806.0, 812.0, 813.0, 817.0, 818.0]    806.0-818.0   \n",
       "0       [806.0, 812.0, 813.0, 817.0, 818.0]    806.0-818.0   \n",
       "0       [863.0, 877.0, 878.0, 879.0, 886.0]    863.0-886.0   \n",
       "0       [806.0, 811.0, 812.0, 817.0, 817.0]    806.0-817.0   \n",
       "0       [351.0, 356.0, 361.0, 365.0, 369.0]    351.0-369.0   \n",
       "0       [403.0, 411.0, 419.0, 431.0, 435.0]    403.0-435.0   \n",
       "0       [880.0, 885.0, 912.0, 932.0, 968.0]    880.0-968.0   \n",
       "0       [604.0, 611.0, 625.0, 632.0, 649.0]    604.0-649.0   \n",
       "0       [880.0, 885.0, 909.0, 935.0, 954.0]    880.0-954.0   \n",
       "0       [604.0, 611.0, 625.0, 631.0, 651.0]    604.0-651.0   \n",
       "0       [392.0, 404.0, 406.0, 432.0, 432.0]    392.0-432.0   \n",
       "0       [387.0, 400.0, 406.0, 420.0, 423.0]    387.0-423.0   \n",
       "0     [888.0, 895.0, 968.0, 1440.0, 1649.0]   888.0-1649.0   \n",
       "0       [271.0, 274.0, 276.0, 282.0, 282.0]    271.0-282.0   \n",
       "0       [449.0, 458.0, 477.0, 510.0, 538.0]    449.0-538.0   \n",
       "0       [521.0, 533.0, 575.0, 729.0, 887.0]    521.0-887.0   \n",
       "0  [1060.0, 1123.0, 1133.0, 1176.0, 3661.0]  1060.0-3661.0   \n",
       "0       [695.0, 772.0, 828.0, 869.0, 954.0]    695.0-954.0   \n",
       "\n",
       "                                         MAE  \\\n",
       "0   [539.01, 544.88, 548.35, 548.62, 554.01]   \n",
       "0   [189.32, 191.26, 195.81, 199.95, 204.91]   \n",
       "0      [304.21, 326.6, 333.4, 333.8, 340.42]   \n",
       "0    [348.45, 360.18, 373.76, 402.8, 404.99]   \n",
       "0    [288.51, 303.81, 304.2, 305.83, 345.36]   \n",
       "0   [322.94, 332.13, 334.76, 347.04, 353.21]   \n",
       "0    [228.1, 238.39, 251.72, 253.29, 265.95]   \n",
       "0    [479.93, 502.99, 507.38, 510.57, 515.9]   \n",
       "0   [313.53, 319.11, 344.25, 361.63, 363.62]   \n",
       "0   [248.59, 249.59, 261.29, 261.74, 261.85]   \n",
       "0   [253.24, 253.97, 254.97, 257.17, 261.38]   \n",
       "0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   [538.52, 544.45, 547.65, 548.19, 553.62]   \n",
       "0   [584.13, 588.87, 593.47, 595.88, 603.25]   \n",
       "0   [539.01, 544.88, 548.35, 548.61, 554.01]   \n",
       "0   [224.17, 224.43, 224.75, 225.25, 229.57]   \n",
       "0   [265.91, 272.71, 272.93, 273.94, 276.48]   \n",
       "0   [599.65, 603.74, 604.48, 606.87, 612.88]   \n",
       "0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   [599.67, 604.08, 604.57, 606.86, 613.25]   \n",
       "0   [638.17, 643.96, 646.54, 646.91, 668.87]   \n",
       "0   [599.57, 603.69, 604.48, 606.85, 612.88]   \n",
       "0    [264.28, 264.31, 264.82, 267.54, 272.7]   \n",
       "0     [292.7, 303.9, 304.22, 304.31, 308.96]   \n",
       "0    [632.76, 639.1, 639.86, 666.64, 686.81]   \n",
       "0   [445.04, 453.04, 464.57, 466.71, 467.52]   \n",
       "0   [636.73, 637.26, 642.49, 676.06, 676.63]   \n",
       "0    [444.05, 453.76, 462.01, 463.62, 467.3]   \n",
       "0     [283.6, 292.89, 296.46, 300.2, 300.94]   \n",
       "0   [283.04, 293.27, 295.01, 299.56, 303.83]   \n",
       "0  [675.77, 678.72, 681.47, 1289.21, 1333.7]   \n",
       "0    [211.21, 215.0, 217.17, 217.75, 218.49]   \n",
       "0   [347.72, 348.02, 352.54, 369.51, 393.18]   \n",
       "0   [383.34, 390.09, 415.22, 547.52, 703.45]   \n",
       "0   [809.57, 825.6, 864.01, 873.12, 3358.85]   \n",
       "0    [524.91, 529.49, 533.47, 547.79, 549.7]   \n",
       "\n",
       "                          Range of MAE  \n",
       "0                        539.01-554.01  \n",
       "0                        189.32-204.91  \n",
       "0                        304.21-340.42  \n",
       "0                        348.45-404.99  \n",
       "0                        288.51-345.36  \n",
       "0                        322.94-353.21  \n",
       "0                         228.1-265.95  \n",
       "0                         479.93-515.9  \n",
       "0                        313.53-363.62  \n",
       "0                        248.59-261.85  \n",
       "0                        253.24-261.38  \n",
       "0                        538.52-553.62  \n",
       "0                        538.52-553.62  \n",
       "0                        584.13-603.25  \n",
       "0                        539.01-554.01  \n",
       "0                        224.17-229.57  \n",
       "0                        265.91-276.48  \n",
       "0                        599.65-612.88  \n",
       "0                        599.67-613.25  \n",
       "0                        599.67-613.25  \n",
       "0                        638.17-668.87  \n",
       "0                        599.57-612.88  \n",
       "0                         264.28-272.7  \n",
       "0                         292.7-308.96  \n",
       "0                        632.76-686.81  \n",
       "0                        445.04-467.52  \n",
       "0                        636.73-676.63  \n",
       "0                         444.05-467.3  \n",
       "0                         283.6-300.94  \n",
       "0                        283.04-303.83  \n",
       "0    675.77001953125-1333.699951171875  \n",
       "0                        211.21-218.49  \n",
       "0                        347.72-393.18  \n",
       "0  383.3399963378906-703.4500122070312  \n",
       "0   809.5700073242188-3358.85009765625  \n",
       "0  524.9099731445312-549.7000122070312  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Train the model with Cross Validation\n",
    "approach='ANN-3HidLayer-Adam-Epoch150-batchsize32'\n",
    "model_obj=model_ANN\n",
    "model_name='ANN'\n",
    "\n",
    "model_traintest_CV(model_obj, model_name, approach,X_train,y_train,n_splits)\n",
    "\n",
    "\n",
    "#Exporting the results to csv\n",
    "df_model_selection.to_csv(\"Model_statistics_upto_Wk4_Tasks\",index = False)\n",
    "\n",
    "df_model_selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the performance statistics for different combinations Layers,variants of Gradient Descent,epochs,batchsize\n",
    "    Approach\t Model_Name\t                                      r2_Scores\t      RMSE\t       MAE\n",
    "\n",
    "    0\tANN-1HidLayer-ADAM-Epoch150-batchsize32\tANN\t                 0.86\t     963.0\t     645.989990\n",
    "    0\tANN-2HidLayer-ADAM-Epoch150-batchsize32\tANN\t                 0.84\t    1009.0\t     721.090027\n",
    "    0\tANN-3HidLayer-ADAM-Epoch150-batchsize32\tANN\t                 0.87\t     923.0\t     664.630005\n",
    "    0\tANN-3HidLayer-ADAM-Epoch200-batchsize32\tANN\t                 0.87\t     927.0\t     649.630005\n",
    "    0\tANN-4HidLayer-ADAM-Epoch200-batchsize32\tANN\t                 0.86\t     949.0\t     691.940002\n",
    "    0\tANN-4HidLayer-ADAM-Epoch200-batchsize32\tANN\t                 0.85\t     968.0\t     697.450012\n",
    "    0\tANN-4HidLayer-ADAM-Epoch200-batchsize32-WithDropout\t         0.77       1225.0\t     872.659973\n",
    "    0\tANN-4HidLayer-ADAM-Epoch300-batchsize32-WithDrropout\t     0.74\t    1294.0\t     890.650024\n",
    "    0\tANN-3HidLayer-ADAM-Epoch200-batchsize32-WithDrropout\t     0.83\t    1046.0\t     800.289978\n",
    "    0\tANN-3HidLayer-ADAM-Epoch150-batchsize32-WithDropout\t         0.76\t    1234.0\t     921.039978\n",
    "    0\tANN-3HidLayer-ADAM-Epoch150-batchsize32-WithDrropout\t     0.82\t    1091.0\t     819.650024\n",
    "    0\tANN-3HidLayer-ADAM-Epoch150-batchsize32\tANN\t                 0.86\t     937.0\t     684.950012\n",
    "    0\tANN-3HidLayer-RMSPROP-Epoch150-batchsize32\tANN\t             0.86\t     944.0\t     669.960022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets extract the best sample , retrain the Neural Network and predict the forcast using Unseen Test Data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=traindata_init[(traindata_init.Sales !=0)&(traindata_init.Store.isin(storeList))]\n",
    "X=traindata.drop(columns=['Sales','Date','Store']).values.astype('float32')\n",
    "y=traindata.Sales.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2-Score: 0.92, Test r2-score: 0.9, for Sample Split: 1\n",
      "Train r2-Score: 0.92, Test r2-score: 0.91, for Sample Split: 2\n",
      "Train r2-Score: 0.93, Test r2-score: 0.88, for Sample Split: 3\n",
      "Train r2-Score: 0.92, Test r2-score: 0.92, for Sample Split: 4\n",
      "Train r2-Score: 0.91, Test r2-score: 0.92, for Sample Split: 5\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Initialize StratifiedKFold Method\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, \n",
    "              random_state=1,\n",
    "              shuffle=True)\n",
    "\n",
    "#Initialize For Loop \n",
    "\n",
    "i=0\n",
    "for train,test in kfold.split(X,y):\n",
    "    i = i+1\n",
    "    X_train,X_test = X[train],X[test]\n",
    "    y_train,y_test = y[train],y[test]\n",
    "    \n",
    "    model_ANN.fit(X_train,y_train,epochs=150,batch_size=32,verbose=0)\n",
    "    test_ds_predicted=model_ANN.predict(X_test)\n",
    "    train_ds_predicted=model_ANN.predict(X_train)\n",
    "    \n",
    "    test_r2_score=round(r2_score(y_true=y_test, y_pred=test_ds_predicted ),2)\n",
    "    train_r2_score=round(r2_score(y_true=y_train, y_pred=train_ds_predicted ),2)\n",
    "    \n",
    "    print(\"Train r2-Score: {}, Test r2-score: {}, for Sample Split: {}\".format(train_r2_score,test_r2_score,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d3dc73e548>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Lets extract the Train and Test sample for split 4\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, \n",
    "              random_state=1,\n",
    "              shuffle=True)\n",
    "i=0\n",
    "for train,test in kfold.split(X,y):\n",
    "    i = i+1\n",
    "    if i == 4:\n",
    "        X_train,X_test,y_train,y_test = X[train],X[test],y[train],y[test]     \n",
    "        \n",
    "#Refit the model with best train and test sample\n",
    "model_ANN.fit(X_train,y_train,epochs=150,batch_size=32,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2-Score: 0.91, Test r2-score: 0.86\n"
     ]
    }
   ],
   "source": [
    "### Evalute the model with Unseen test Data(X_test)\n",
    "X_test=test_hiddata.drop(columns=['Sales','Date','Store']).values.astype('float32')\n",
    "y_test=test_hiddata.Sales.values.astype('float32')\n",
    "\n",
    "test_ds_predicted=model_ANN.predict(X_test)\n",
    "train_ds_predicted=model_ANN.predict(X_train)\n",
    "    \n",
    "test_r2_score=round(r2_score(y_true=y_test, y_pred=test_ds_predicted ),2)\n",
    "train_r2_score=round(r2_score(y_true=y_train, y_pred=train_ds_predicted ),2)\n",
    "    \n",
    "print(\"Train r2-Score: {}, Test r2-score: {}\".format(train_r2_score,test_r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Observations\n",
    "    1. ANN test r2 score is 86 % with best settings after 5 fold cross validation.What it means is that ANN performance is still below par  as compared to Traditional ML model for this use case. One of the reason could be insuficient data. We have trained our model with just 10 stores data. Retraining the model with full set of data might give better score. This needs to be tested separately.\n",
    "    2. Clustering the data and training separately within each cluster did not improve the performance\n",
    "    3. The best performing models for this usecase are\n",
    "        1. XGBoost Regressor  with Test R2 Score of 99% \n",
    "        2. Gradiant Boosting Regressor with Test R2 Score of 99% \n",
    "        3. Random Forest Regressor with Test R2 Score of 97%\n",
    "        4. ANN-3HidLayer-Adam-Epoch150-batchsize32 with Test R2 Score of 86%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
